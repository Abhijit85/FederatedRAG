{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22d6e274",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "258146e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, f1_score\n",
    "from math import sqrt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9b37dc",
   "metadata": {},
   "source": [
    "# Step 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b51e15f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3x/spcgg7yj437cqttlyc5hmc5h0000gn/T/ipykernel_45601/4179641983.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  triples['head'] = triples['user'].map(entity_to_id)\n"
     ]
    }
   ],
   "source": [
    "# Load MovieLens 100K dataset\n",
    "ratings = pd.read_csv('/Users/abhi/GitHUB/FederatedRAG/DataSets/ml-100k/u.data', sep='\\t', names=['user', 'movie', 'rating', 'timestamp'], engine='python')\n",
    "\n",
    "# Create knowledge graph triples\n",
    "ratings['relation'] = 'rates'\n",
    "triples = ratings[['user', 'relation', 'movie']]\n",
    "\n",
    "# Create entity and relation mappings\n",
    "all_entities = list(set(ratings['user']).union(set(ratings['movie'])))\n",
    "entity_to_id = {entity: idx for idx, entity in enumerate(all_entities)}\n",
    "id_to_entity = {idx: entity for entity, idx in entity_to_id.items()}\n",
    "relation_to_id = {'rates': 0}\n",
    "id_to_relation = {0: 'rates'}\n",
    "\n",
    "# Map entities and relations to IDs\n",
    "triples['head'] = triples['user'].map(entity_to_id)\n",
    "triples['tail'] = triples['movie'].map(entity_to_id)\n",
    "triples['relation'] = triples['relation'].map(relation_to_id)\n",
    "triples = triples[['head', 'relation', 'tail']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddddd7ae",
   "metadata": {},
   "source": [
    "# Step 2: Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2c2c3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class KnowledgeGraphDataset(Dataset):\n",
    "    def __init__(self, triples):\n",
    "        self.triples = triples.values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.triples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.triples[idx]\n",
    "\n",
    "# Create dataset and dataloader\n",
    "kg_dataset = KnowledgeGraphDataset(triples)\n",
    "kg_dataloader = DataLoader(kg_dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9738de1",
   "metadata": {},
   "source": [
    "# Step 3: Define the TransE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c48a7e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TransEModel(nn.Module):\n",
    "    def __init__(self, num_entities, num_relations, embedding_dim):\n",
    "        super(TransEModel, self).__init__()\n",
    "        self.entity_embeddings = nn.Embedding(num_entities, embedding_dim)\n",
    "        self.relation_embeddings = nn.Embedding(num_relations, embedding_dim)\n",
    "\n",
    "    def forward(self, head, relation, tail):\n",
    "        head_embedding = self.entity_embeddings(head)\n",
    "        relation_embedding = self.relation_embeddings(relation)\n",
    "        tail_embedding = self.entity_embeddings(tail)\n",
    "        return head_embedding + relation_embedding - tail_embedding\n",
    "\n",
    "    def get_embeddings(self):\n",
    "        return self.entity_embeddings.weight.detach().cpu().numpy()\n",
    "\n",
    "# Function to initialize model parameters\n",
    "def initialize_model(embedding_dim=50, learning_rate=0.01, margin=1.0):\n",
    "    global model, criterion, optimizer\n",
    "    model = TransEModel(num_entities, num_relations, embedding_dim).to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "    criterion = nn.MarginRankingLoss(margin=margin)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed06cc27",
   "metadata": {},
   "source": [
    "# Initialize model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7d4920b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_entities = len(entity_to_id)\n",
    "num_relations = len(relation_to_id)\n",
    "initialize_model(embedding_dim=50, learning_rate=0.01, margin=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d35791",
   "metadata": {},
   "source": [
    "# Step 4: Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6eb1402c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_negative_samples(batch):\n",
    "    batch_size = batch.shape[0]\n",
    "    negative_samples = batch.clone()\n",
    "    for i in range(batch_size):\n",
    "        if np.random.rand() < 0.5:\n",
    "            negative_samples[i, 2] = np.random.choice(num_entities)  # Replace tail\n",
    "        else:\n",
    "            negative_samples[i, 0] = np.random.choice(num_entities)  # Replace head\n",
    "    return negative_samples\n",
    "\n",
    "def train_model(num_epochs=10):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch in kg_dataloader:\n",
    "            batch = batch.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "\n",
    "            # Positive samples\n",
    "            head, relation, tail = batch[:, 0], batch[:, 1], batch[:, 2]\n",
    "            pos_scores = torch.norm(model(head, relation, tail), p=2, dim=1)\n",
    "\n",
    "            # Negative samples\n",
    "            negative_batch = generate_negative_samples(batch)\n",
    "            neg_head, neg_relation, neg_tail = negative_batch[:, 0], negative_batch[:, 1], negative_batch[:, 2]\n",
    "            neg_scores = torch.norm(model(neg_head, neg_relation, neg_tail), p=2, dim=1)\n",
    "\n",
    "            # Calculate loss\n",
    "            target = torch.ones_like(pos_scores)\n",
    "            loss = criterion(pos_scores, neg_scores, target)\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {total_loss}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e6a795",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e24386a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 280.82981127500534\n",
      "Epoch 2, Loss: 280.6624404489994\n",
      "Epoch 3, Loss: 271.064123660326\n",
      "Epoch 4, Loss: 269.6384253948927\n",
      "Epoch 5, Loss: 267.86956648528576\n",
      "Epoch 6, Loss: 261.50204269587994\n",
      "Epoch 7, Loss: 262.65105402469635\n",
      "Epoch 8, Loss: 257.9821886867285\n",
      "Epoch 9, Loss: 256.6142937541008\n",
      "Epoch 10, Loss: 255.15003564953804\n",
      "Epoch 11, Loss: 254.77102488279343\n",
      "Epoch 12, Loss: 255.4610629826784\n",
      "Epoch 13, Loss: 253.64148126542568\n",
      "Epoch 14, Loss: 251.7117628455162\n",
      "Epoch 15, Loss: 248.0394583940506\n",
      "Epoch 16, Loss: 248.79728235304356\n",
      "Epoch 17, Loss: 247.320734500885\n",
      "Epoch 18, Loss: 248.19750559329987\n",
      "Epoch 19, Loss: 246.27577474713326\n",
      "Epoch 20, Loss: 243.11865992844105\n",
      "Epoch 21, Loss: 243.50109888613224\n",
      "Epoch 22, Loss: 242.17093713581562\n",
      "Epoch 23, Loss: 242.40418204665184\n",
      "Epoch 24, Loss: 242.8535503745079\n",
      "Epoch 25, Loss: 241.09464220702648\n",
      "Epoch 26, Loss: 239.61285869777203\n",
      "Epoch 27, Loss: 237.74580751359463\n",
      "Epoch 28, Loss: 237.7809741050005\n",
      "Epoch 29, Loss: 238.19058573246002\n",
      "Epoch 30, Loss: 236.6528378725052\n",
      "Epoch 31, Loss: 238.34816285967827\n",
      "Epoch 32, Loss: 237.5559914112091\n",
      "Epoch 33, Loss: 236.54036505520344\n",
      "Epoch 34, Loss: 235.0016776174307\n",
      "Epoch 35, Loss: 235.6448691636324\n",
      "Epoch 36, Loss: 233.4374673962593\n",
      "Epoch 37, Loss: 236.46356466412544\n",
      "Epoch 38, Loss: 234.4440861493349\n",
      "Epoch 39, Loss: 234.96059280633926\n",
      "Epoch 40, Loss: 234.5668138116598\n",
      "Epoch 41, Loss: 234.1249785721302\n",
      "Epoch 42, Loss: 232.12996271252632\n",
      "Epoch 43, Loss: 228.2506773918867\n",
      "Epoch 44, Loss: 229.83432932198048\n",
      "Epoch 45, Loss: 230.58933176100254\n",
      "Epoch 46, Loss: 229.0689763277769\n",
      "Epoch 47, Loss: 230.74802993237972\n",
      "Epoch 48, Loss: 230.66510854661465\n",
      "Epoch 49, Loss: 228.15592029690742\n",
      "Epoch 50, Loss: 229.93621444702148\n"
     ]
    }
   ],
   "source": [
    "train_model(num_epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f4beda",
   "metadata": {},
   "source": [
    "# Step 5: Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4231d0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to /Users/abhi/GitHUB/FederatedRAG/TunedModels/TransE_fine_tuned_model.pth\n"
     ]
    }
   ],
   "source": [
    "def save_model(model, file_path):\n",
    "    version = 1\n",
    "    while os.path.exists(file_path):\n",
    "        file_path = f\"TransE_fine_tuned_model_v{version}.pth\"\n",
    "        version += 1  # If a file with the specified name already exists, the function appends a version number to the file name\n",
    "    torch.save(model.state_dict(), file_path)\n",
    "    print(f\"Model saved to {file_path}\")\n",
    "# Change the path based on local directory\n",
    "save_model(model, \"/Users/abhi/GitHUB/FederatedRAG/TunedModels/TransE_fine_tuned_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5575c25",
   "metadata": {},
   "source": [
    "# Step 6: Prediction and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9a7aab08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(triples, model, entity_to_id, device):\n",
    "    hits_at_10 = 0\n",
    "    mean_rank = 0\n",
    "    mean_reciprocal_rank = 0\n",
    "    total_samples = len(triples)\n",
    "\n",
    "    for head, relation, tail in triples:\n",
    "        head, relation, tail = torch.tensor(head).to(device), torch.tensor(relation).to(device), torch.tensor(tail).to(device)\n",
    "\n",
    "        head_embedding = model.entity_embeddings(head)\n",
    "        relation_embedding = model.relation_embeddings(relation)\n",
    "        target_tail_embedding = model.entity_embeddings(tail)\n",
    "\n",
    "        # Compute scores for all entities as tail\n",
    "        all_entities = torch.arange(model.entity_embeddings.num_embeddings).to(device)\n",
    "        all_entity_embeddings = model.entity_embeddings(all_entities)\n",
    "        scores = torch.norm(head_embedding + relation_embedding - all_entity_embeddings, p=2, dim=1)\n",
    "\n",
    "        # Rank entities based on the scores\n",
    "        sorted_indices = torch.argsort(scores)\n",
    "        rank = (sorted_indices == tail).nonzero(as_tuple=True)[0].item() + 1\n",
    "\n",
    "        # Update metrics\n",
    "        mean_rank += rank\n",
    "        mean_reciprocal_rank += 1 / rank\n",
    "        if rank <= 10:\n",
    "            hits_at_10 += 1\n",
    "\n",
    "    hits_at_10 = hits_at_10 / total_samples\n",
    "    mean_rank = mean_rank / total_samples\n",
    "    mean_reciprocal_rank = mean_reciprocal_rank / total_samples\n",
    "\n",
    "    print(f\"Hits@10: {hits_at_10}\")\n",
    "    print(f\"Mean Rank: {mean_rank}\")\n",
    "    print(f\"Mean Reciprocal Rank (MRR): {mean_reciprocal_rank}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11468b3",
   "metadata": {},
   "source": [
    "# Run evaluation on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d2a0f3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10: 0.00096\n",
      "Mean Rank: 1465.12757\n",
      "Mean Reciprocal Rank (MRR): 0.0016460369044324753\n"
     ]
    }
   ],
   "source": [
    "# Run evaluation\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "evaluate_triples = triples.values.tolist()\n",
    "calculate_metrics(evaluate_triples, model, entity_to_id, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
