{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhijit85/FederatedRAG/blob/main/TransEE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmSOksvuoAz3"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRLotX9cpCWr"
      },
      "outputs": [],
      "source": [
        "# whether you are using a GPU to run this Colab\n",
        "use_gpu = True\n",
        "# whether you are using a custom GCE env to run the Colab (uses different CUDA)\n",
        "custom_GCE_env = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFbWsOOboAz5",
        "outputId": "ac744c76-361d-45f3-df76-5be0bb4f092a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.57.4)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.10.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n"
          ]
        }
      ],
      "source": [
        "%pip install openai\n",
        "%pip install python-dotenv\n",
        "# %pip install torch-geometric\n",
        "# %pip install torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
        "# %pip install torch-sparse -f https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "import os\n",
        "import re\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "# from torch_geometric.data import InMemoryDataset, DataLoader\n",
        "# import torch_geometric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uj9IXX0LoAz8"
      },
      "source": [
        "# Data Preparation and Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ktbb1Ambdnxv"
      },
      "outputs": [],
      "source": [
        "class CustomDataset:\n",
        "    def __init__(self, data_path: str):\n",
        "        \"\"\"\n",
        "        Custom Dataset class for loading and processing data without PyTorch Geometric.\n",
        "\n",
        "        Args:\n",
        "            data_path (str): Path to the dataset directory.\n",
        "        \"\"\"\n",
        "\n",
        "        #data_path = '/Users/abhi/GitHUB/FederatedRAG1/DataSets/FB15k-237'\n",
        "        # Paths to files\n",
        "        self.entity_dict_path = os.path.join(data_path, 'entities.dict')\n",
        "        self.relation_dict_path = os.path.join(data_path, 'relations.dict')\n",
        "        self.train_data_path = os.path.join(data_path, 'train.txt')\n",
        "        self.valid_data_path = os.path.join(data_path, 'valid.txt')\n",
        "        self.test_data_path = os.path.join(data_path, 'test.txt')\n",
        "\n",
        "        # Load dictionaries and datasets\n",
        "        self.entity_dict = self._read_dict(self.entity_dict_path)\n",
        "        self.relation_dict = self._read_dict(self.relation_dict_path)\n",
        "\n",
        "        self.train_data = self._read_data(self.train_data_path)\n",
        "        self.valid_data = self._read_data(self.valid_data_path)\n",
        "        self.test_data = self._read_data(self.test_data_path)\n",
        "\n",
        "        self.num_entities = len(self.entity_dict)\n",
        "        self.num_relations = len(self.relation_dict)\n",
        "\n",
        "    # def _read_dict(self, file_path):\n",
        "    #     \"\"\"Read a dictionary file mapping strings to integers.\"\"\"\n",
        "    #     with open(file_path, 'r') as f:\n",
        "    #         lines = f.readlines()\n",
        "    #     return {line.split('\\t')[0]: int(line.split('\\t')[1]) for line in lines}\n",
        "\n",
        "    def _read_dict(self, file_path: str):\n",
        "        \"\"\"\n",
        "        Read entity / relation dict.\n",
        "        Format: dict({id: entity / relation})\n",
        "        \"\"\"\n",
        "\n",
        "        element_dict = {}\n",
        "        with open(file_path, 'r') as f:\n",
        "            for line in f:\n",
        "                id_, element = line.strip().split('\\t')\n",
        "                element_dict[element] = int(id_)\n",
        "\n",
        "        return element_dict\n",
        "\n",
        "    def _read_data(self, file_path):\n",
        "        \"\"\"Read triples data and map to indices.\"\"\"\n",
        "        with open(file_path, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "        triples = [line.strip().split('\\t') for line in lines]\n",
        "        return [(self.entity_dict[h], self.relation_dict[r], self.entity_dict[t]) for h, r, t in triples]\n",
        "\n",
        "    def get_edge_indices_and_types(self, data):\n",
        "        \"\"\"Convert triples into edge indices and types for PyTorch tensors.\"\"\"\n",
        "        heads, relations, tails = zip(*data)\n",
        "        edge_index = torch.tensor([heads, tails], dtype=torch.long)  # Shape: (2, num_edges)\n",
        "        edge_type = torch.tensor(relations, dtype=torch.long)  # Shape: (num_edges,)\n",
        "        return edge_index, edge_type\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gh7tKibqoAz9"
      },
      "source": [
        "# TransGPT Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dt4KLlz5oAz9"
      },
      "outputs": [],
      "source": [
        "class TransEEnhanced(nn.Module):\n",
        "    def __init__(self, num_entities, num_relations, embedding_dim, margin, distance_metric=\"L1\",\n",
        "                 gamma=12.0, phase_weight=0.5, modulus_weight=1.0, epsilon=2.0):\n",
        "        super(TransEEnhanced, self).__init__()\n",
        "\n",
        "        # Basic TransE embeddings\n",
        "        self.entity_modulus = nn.Embedding(num_entities, embedding_dim)\n",
        "        self.entity_phase = nn.Embedding(num_entities, embedding_dim)\n",
        "        self.relation_modulus = nn.Embedding(num_relations, embedding_dim)\n",
        "        self.relation_phase = nn.Embedding(num_relations, embedding_dim)\n",
        "\n",
        "        # Margin and distance settings\n",
        "        self.margin = margin\n",
        "        self.distance_metric = distance_metric\n",
        "\n",
        "        # Hyperbolic and scaling settings\n",
        "        self.gamma = nn.Parameter(torch.Tensor([gamma]), requires_grad=False)\n",
        "        self.embedding_range = nn.Parameter(\n",
        "            torch.Tensor([(self.gamma.item() + epsilon) / embedding_dim]), requires_grad=False\n",
        "        )\n",
        "\n",
        "        # Weights for phase and modulus\n",
        "        self.phase_weight = phase_weight\n",
        "        self.modulus_weight = modulus_weight\n",
        "\n",
        "        # Initialization\n",
        "        nn.init.uniform_(self.entity_modulus.weight, a=-self.embedding_range.item(), b=self.embedding_range.item())\n",
        "        nn.init.uniform_(self.entity_phase.weight, a=-np.pi, b=np.pi)\n",
        "        nn.init.uniform_(self.relation_modulus.weight, a=-self.embedding_range.item(), b=self.embedding_range.item())\n",
        "        nn.init.uniform_(self.relation_phase.weight, a=-np.pi, b=np.pi)\n",
        "\n",
        "    def forward(self, head, relation, tail):\n",
        "        h_mod = self.entity_modulus(head)\n",
        "        h_phase = self.entity_phase(head)\n",
        "        r_mod = self.relation_modulus(relation)\n",
        "        r_phase = self.relation_phase(relation)\n",
        "        t_mod = self.entity_modulus(tail)\n",
        "        t_phase = self.entity_phase(tail)\n",
        "\n",
        "        # Modulus scoring: hyperbolic-inspired adjustment\n",
        "        modulus_score = torch.norm(h_mod * r_mod - t_mod, p=2, dim=-1)\n",
        "\n",
        "        # Phase scoring: advanced angular consistency\n",
        "        phase_diff = torch.abs(torch.sin((h_phase + r_phase - t_phase) / 2))\n",
        "        phase_score = torch.sum(phase_diff, dim=-1)\n",
        "\n",
        "        # Weighted combined score\n",
        "        score = self.modulus_weight * modulus_score + self.phase_weight * phase_score\n",
        "        return score\n",
        "\n",
        "    def compute_loss(self, positive_score, negative_score):\n",
        "        # Margin-based ranking loss\n",
        "        base_loss = F.relu(self.margin + positive_score - negative_score)\n",
        "\n",
        "        # Regularization terms for modulus and phase\n",
        "        modulus_regularization = torch.sum(torch.norm(self.entity_modulus.weight, p=2, dim=-1))\n",
        "        phase_regularization = torch.sum(torch.norm(self.entity_phase.weight, p=2, dim=-1))\n",
        "\n",
        "        # Total loss with regularization\n",
        "        total_loss = base_loss.mean() + 1e-4 * (modulus_regularization + phase_regularization)\n",
        "        return total_loss\n",
        "\n",
        "# Helper function to create corrupted edges\n",
        "def create_corrupted_edge_index(edge_index, edge_type, num_entities):\n",
        "    corrupt_head_or_tail = torch.randint(high=2, size=edge_type.size(),\n",
        "                                         device=edge_index.device)\n",
        "    random_entities = torch.randint(high=num_entities,\n",
        "                                     size=edge_type.size(), device=edge_index.device)\n",
        "    # corrupt when 1, otherwise regular head\n",
        "    heads = torch.where(corrupt_head_or_tail == 1, random_entities,\n",
        "                        edge_index[0, :])\n",
        "    # corrupt when 0, otherwise regular tail\n",
        "    tails = torch.where(corrupt_head_or_tail == 0, random_entities,\n",
        "                        edge_index[1, :])\n",
        "    return torch.stack([heads, tails], dim=0)\n",
        "\n",
        "# # Helper function to prompt predictions to LLM\n",
        "\n",
        "# def refine_predictions_with_llm(predictions, batch_edge_index, batch_edge_type, model, entity_dict, relation_dict):\n",
        "#     # Decode the indices into human-readable entity and relation names\n",
        "#     head_entities = [entity_dict[int(head)] for head in batch_edge_index[0].tolist()]\n",
        "#     relation_names = [relation_dict[int(rel)] for rel in batch_edge_type.tolist()]\n",
        "#     predicted_tails = [entity_dict[int(torch.argmin(pred))] for pred in predictions]\n",
        "\n",
        "#     # Format the data for LLM\n",
        "#     input_data = []\n",
        "#     for h, r, t in zip(head_entities, relation_names, predicted_tails):\n",
        "#         input_data.append(f\"Head: {h}, Relation: {r}, Predicted Tail: {t}\")\n",
        "\n",
        "    # # Prompt the LLM (GPT-3.5-turbo/GPT-4 )\n",
        "    # api_key = \"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\"\n",
        "    # if not api_key:\n",
        "    #     raise ValueError(\"OpenAI API key not found in environment variables\")\n",
        "\n",
        "    # client = OpenAI(api_key=api_key)\n",
        "    # # openai.api_key = \"your-openai-api-key\"\n",
        "    # response = client.chat.completions.create(\n",
        "    #     model=\"gpt-4\", # gpt-3.5-turbo\n",
        "    #     messages=[\n",
        "    #         {\"role\": \"system\", \"content\": \"You are an expert in knowledge graphs and TransE embeddings.\"},\n",
        "    #         {\"role\": \"user\", \"content\": \"Please evaluate and improve the following predictions:\\n\" + \"\\n\".join(input_data)}\n",
        "    #     ]\n",
        "    # )\n",
        "\n",
        "    # # Parse LLM response\n",
        "    # # refined_predictions = response['choices'][0]['message']['content']\n",
        "    # refined_predictions = response.choices[0].message.content\n",
        "    # print(\"Refined Predictions from LLM:\")\n",
        "    # print(refined_predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXiKs2dKoAz-"
      },
      "source": [
        "# Train Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-VlS8124rZw"
      },
      "source": [
        "## Model: TransE\n",
        "**Embeddings:**\n",
        "Each entity and relation is represented as a vector in a high-dimensional space.\n",
        "The embeddings are initialized randomly and updated during training.\n",
        "**Distance Metric:**\n",
        "TransE predicts relationships by minimizing the distance between embeddings of head + relation - tail.\n",
        "A lower distance indicates a more likely relationship."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAtTXKqh5Mdo"
      },
      "source": [
        "## How Is the LLM Used?\n",
        "1. Prediction Refinement\n",
        "After the TransE model predicts relationships (e.g., a tail entity for a given head and relation), these predictions are passed to the LLM.\n",
        "The LLM evaluates the predictions, identifies errors, and suggests corrections or more plausible results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "ruby"
        },
        "id": "rnLn4HqKdnxx"
      },
      "outputs": [],
      "source": [
        "def train(model, data, optimizer, device, entity_dict, relation_dict, epochs=50, batch_size=128, valid_freq=5):\n",
        "    train_edge_index = data.train_edge_index.to(device)\n",
        "    train_edge_type = data.train_edge_type.to(device)\n",
        "    valid_edge_index = data.valid_edge_index.to(device)\n",
        "    valid_edge_type = data.valid_edge_type.to(device)\n",
        "\n",
        "    best_valid_score = 0\n",
        "    valid_scores = None\n",
        "    test_scores = None\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "\n",
        "        # Normalize entity embeddings (modulus only)\n",
        "        entities_modulus_norm = torch.norm(model.entity_modulus.weight.data, dim=1, keepdim=True)\n",
        "        model.entity_modulus.weight.data = model.entity_modulus.weight.data / entities_modulus_norm\n",
        "\n",
        "        # Shuffle the training data\n",
        "        num_triples = train_edge_type.size(0)\n",
        "        shuffled_indices = torch.randperm(num_triples)\n",
        "        shuffled_edge_index = train_edge_index[:, shuffled_indices]\n",
        "        shuffled_edge_type = train_edge_type[shuffled_indices]\n",
        "\n",
        "        negative_edge_index = create_corrupted_edge_index(shuffled_edge_index, shuffled_edge_type, data.num_entities)\n",
        "\n",
        "        total_loss = 0\n",
        "        total_size = 0\n",
        "\n",
        "        for batch_start in range(0, num_triples, batch_size):\n",
        "            batch_end = min(batch_start + batch_size, num_triples)\n",
        "            batch_edge_index = shuffled_edge_index[:, batch_start:batch_end]\n",
        "            batch_negative_edge_index = negative_edge_index[:, batch_start:batch_end]\n",
        "            batch_edge_type = shuffled_edge_type[batch_start:batch_end]\n",
        "\n",
        "            # Compute positive and negative scores for TransEEnhanced\n",
        "            positive_score = model(batch_edge_index[0], batch_edge_type, batch_edge_index[1])\n",
        "            negative_score = model(batch_negative_edge_index[0], batch_edge_type, batch_negative_edge_index[1])\n",
        "\n",
        "            # Compute loss using TransEEnhanced's loss function\n",
        "            loss = model.compute_loss(positive_score, negative_score)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item() * (batch_end - batch_start)\n",
        "            total_size += batch_end - batch_start\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / total_size:.4f}\")\n",
        "\n",
        "        # Validation at regular intervals\n",
        "        if (epoch + 1) % valid_freq == 0:\n",
        "            mrr_score, mr_score, hits_at_10 = evaluate_model(\n",
        "                model, valid_edge_index, valid_edge_type, data.num_entities, device\n",
        "            )\n",
        "            print(f\"Validation score: MRR = {mrr_score:.4f}, MR = {mr_score:.4f}, Hits@10 = {hits_at_10:.4f}\")\n",
        "\n",
        "            # Track best validation score\n",
        "            if mrr_score > best_valid_score:\n",
        "                best_valid_score = mrr_score\n",
        "                test_mrr, test_mr, test_hits_at_10 = evaluate_model(\n",
        "                    model, data.test_edge_index.to(device), data.test_edge_type.to(device), data.num_entities, device\n",
        "                )\n",
        "                test_scores = (test_mrr, test_mr, test_hits_at_10)\n",
        "\n",
        "    print(f\"Test scores from the best model (MMR, MR, Hits@10): {test_scores}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyUVJhNroAz-"
      },
      "source": [
        "# Evaluate Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tzLhqtE4XK_"
      },
      "source": [
        "## Prediction:\n",
        "After training, the model can predict missing relationships by ranking possible tail entities for a given (head, relation, ?).\n",
        "Example Query:\n",
        "Input: (Steve Jobs, FounderOf, ?)\n",
        "Output: Apple (highest-ranked entity)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jY6DkHKgoAz_"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, edge_index, edge_type, num_entities, device, eval_batch_size=64):\n",
        "    model.eval()\n",
        "    num_triples = edge_type.size(0)\n",
        "    mrr_score = 0\n",
        "    mr_score = 0\n",
        "    hits_at_10 = 0\n",
        "    num_predictions = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx in range(math.ceil(num_triples / eval_batch_size)):\n",
        "            batch_start = batch_idx * eval_batch_size\n",
        "            batch_end = min((batch_idx + 1) * eval_batch_size, num_triples)\n",
        "            batch_edge_index = edge_index[:, batch_start:batch_end]\n",
        "            batch_edge_type = edge_type[batch_start:batch_end]\n",
        "            batch_size = batch_edge_type.size(0)\n",
        "\n",
        "            all_entities = torch.arange(num_entities, device=device).unsqueeze(0).repeat(batch_size, 1)\n",
        "            head_repeated = batch_edge_index[0, :].reshape(-1, 1).repeat(1, num_entities)\n",
        "            relation_repeated = batch_edge_type.reshape(-1, 1).repeat(1, num_entities)\n",
        "\n",
        "            head_squeezed = head_repeated.reshape(-1)\n",
        "            relation_squeezed = relation_repeated.reshape(-1)\n",
        "            all_entities_squeezed = all_entities.reshape(-1)\n",
        "\n",
        "            entity_index_replaced_tail = torch.stack((head_squeezed, all_entities_squeezed))\n",
        "            predictions = model(entity_index_replaced_tail[0], relation_squeezed, entity_index_replaced_tail[1])\n",
        "            predictions = predictions.reshape(batch_size, -1)\n",
        "            gt = batch_edge_index[1, :].reshape(-1, 1)\n",
        "\n",
        "            mrr_score += mrr(predictions, gt)\n",
        "            mr_score += mr(predictions, gt)\n",
        "            hits_at_10 += hit_at_k(predictions, gt, device=device, k=10)\n",
        "            num_predictions += batch_size\n",
        "\n",
        "    mrr_score = mrr_score / num_predictions\n",
        "    mr_score = mr_score / num_predictions\n",
        "    hits_at_10 = hits_at_10 / num_predictions\n",
        "    return mrr_score, mr_score, hits_at_10\n",
        "\n",
        "# Metric Functions\n",
        "def mrr(predictions, gt):\n",
        "    indices = predictions.argsort()\n",
        "    return (1.0 / (indices == gt).nonzero()[:, 1].float().add(1.0)).sum().item()\n",
        "\n",
        "def mr(predictions, gt):\n",
        "    indices = predictions.argsort()\n",
        "    return ((indices == gt).nonzero()[:, 1].float().add(1.0)).sum().item()\n",
        "\n",
        "def hit_at_k(predictions, gt, device, k=10):\n",
        "    zero_tensor = torch.tensor([0], device=device)\n",
        "    one_tensor = torch.tensor([1], device=device)\n",
        "    _, indices = predictions.topk(k=k, largest=False)\n",
        "    return torch.where(indices == gt, one_tensor, zero_tensor).sum().item()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4a5ovUh4oAz_"
      },
      "source": [
        "# Start Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6FOxlII4jEq"
      },
      "source": [
        "## Positive Triplets:\n",
        "The dataset provides positive examples in the form of valid (head, relation, tail) triplets.\n",
        "## Negative Sampling:\n",
        "For each positive triplet, a corrupted version is generated by replacing either the head or tail with a random entity.\n",
        "## Loss Function:\n",
        "The model uses margin-based ranking loss:\n",
        "Ensures valid triplets are closer in embedding space than invalid ones by at least a predefined margin."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpyhhj7toAz_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00a64ccd-5f84-4964-d825-cbe594eb4cd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 66.7723\n",
            "Epoch 2/10, Loss: 79.7920\n",
            "Epoch 3/10, Loss: 80.0953\n",
            "Epoch 4/10, Loss: 80.3803\n",
            "Epoch 5/10, Loss: 80.4606\n",
            "Validation score: MRR = 0.0064, MR = 7336.6015, Hits@10 = 0.0067\n",
            "Epoch 6/10, Loss: 80.5395\n"
          ]
        }
      ],
      "source": [
        "lr = 0.1\n",
        "use_gpu = torch.cuda.is_available()\n",
        "if use_gpu:\n",
        "    epochs = 10\n",
        "    valid_freq = 5\n",
        "else:\n",
        "    epochs = 10\n",
        "    valid_freq = 10\n",
        "\n",
        "device = torch.device('cuda' if use_gpu else 'cpu')\n",
        "\n",
        "# Load dataset using CustomDataset class\n",
        "data_path = '/content/sample_data'\n",
        "dataset = CustomDataset(data_path)\n",
        "data = dataset\n",
        "\n",
        "# Extract edge indices and types\n",
        "train_edge_index, train_edge_type = dataset.get_edge_indices_and_types(dataset.train_data)\n",
        "valid_edge_index, valid_edge_type = dataset.get_edge_indices_and_types(dataset.valid_data)\n",
        "test_edge_index, test_edge_type = dataset.get_edge_indices_and_types(dataset.test_data)\n",
        "\n",
        "model = TransEEnhanced(data.num_entities, data.num_relations, embedding_dim=400, margin=2.0).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "entity_dict = dataset.entity_dict  # Load entity dictionary from dataset\n",
        "relation_dict = dataset.relation_dict  # Load relation dictionary from dataset\n",
        "\n",
        "# Create a data object with the extracted edge indices and types\n",
        "data.train_edge_index = train_edge_index\n",
        "data.train_edge_type = train_edge_type\n",
        "data.valid_edge_index = valid_edge_index\n",
        "data.valid_edge_type = valid_edge_type\n",
        "data.test_edge_index = test_edge_index\n",
        "data.test_edge_type = test_edge_type\n",
        "\n",
        "# Training\n",
        "train(\n",
        "    model=model,\n",
        "    data=data,\n",
        "    optimizer=optimizer,\n",
        "    device=device,\n",
        "    entity_dict=entity_dict,\n",
        "    relation_dict=relation_dict,\n",
        "    epochs=epochs,  # Use the epochs variable defined earlier\n",
        "    batch_size=64,\n",
        "    valid_freq=valid_freq  # Use the valid_freq variable defined earlier\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vs_oJCzJ3am6"
      },
      "source": [
        "# Example Workflow:\n",
        "## Input:\n",
        "\n",
        "**Dataset**: (Barack Obama, PresidentOf, United States), (Elon Musk, FounderOf, Tesla).\n",
        "**Embedding Initialization**:\n",
        "\n",
        "**Entities**: Barack Obama, United States, Elon Musk, Tesla.\n",
        "**Relations**: PresidentOf, FounderOf.\n",
        "**Training:**\n",
        "\n",
        "**Positive Triplets**: (Barack Obama, PresidentOf, United States).\n",
        "**Negative Sampling**: (Barack Obama, PresidentOf, RandomEntity).\n",
        "Evaluation:\n",
        "\n",
        "Metrics like **MRR, MR,** and **Hits@10** are computed during validation to measure the model’s performance.\n",
        "Prediction:\n",
        "\n",
        "**Query**: *(Elon Musk, FounderOf, ?)*\n",
        "**Prediction**: Tesla (most likely tail).\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}