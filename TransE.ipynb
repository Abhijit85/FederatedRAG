{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhijit85/FederatedRAG/blob/main/TransE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmSOksvuoAz3"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "MRLotX9cpCWr"
      },
      "outputs": [],
      "source": [
        "# whether you are using a GPU to run this Colab\n",
        "use_gpu = True\n",
        "# whether you are using a custom GCE env to run the Colab (uses different CUDA)\n",
        "custom_GCE_env = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFbWsOOboAz5",
        "outputId": "707f0082-2475-4394-809f-67464b7ea564"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.57.4)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.10.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.1)\n"
          ]
        }
      ],
      "source": [
        "%pip install openai\n",
        "%pip install python-dotenv\n",
        "# %pip install torch-geometric\n",
        "# %pip install torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
        "# %pip install torch-sparse -f https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "import os\n",
        "import re\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "# from torch_geometric.data import InMemoryDataset, DataLoader\n",
        "# import torch_geometric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uj9IXX0LoAz8"
      },
      "source": [
        "# Data Preparation and Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Ktbb1Ambdnxv"
      },
      "outputs": [],
      "source": [
        "class CustomDataset:\n",
        "    def __init__(self, data_path: str):\n",
        "        \"\"\"\n",
        "        Custom Dataset class for loading and processing data without PyTorch Geometric.\n",
        "\n",
        "        Args:\n",
        "            data_path (str): Path to the dataset directory.\n",
        "        \"\"\"\n",
        "\n",
        "        #data_path = '/Users/abhi/GitHUB/FederatedRAG1/DataSets/FB15k-237'\n",
        "        # Paths to files\n",
        "        self.entity_dict_path = os.path.join(data_path, 'entities.dict')\n",
        "        self.relation_dict_path = os.path.join(data_path, 'relations.dict')\n",
        "        self.train_data_path = os.path.join(data_path, 'train.txt')\n",
        "        self.valid_data_path = os.path.join(data_path, 'valid.txt')\n",
        "        self.test_data_path = os.path.join(data_path, 'test.txt')\n",
        "\n",
        "        # Load dictionaries and datasets\n",
        "        self.entity_dict = self._read_dict(self.entity_dict_path)\n",
        "        self.relation_dict = self._read_dict(self.relation_dict_path)\n",
        "\n",
        "        self.train_data = self._read_data(self.train_data_path)\n",
        "        self.valid_data = self._read_data(self.valid_data_path)\n",
        "        self.test_data = self._read_data(self.test_data_path)\n",
        "\n",
        "        self.num_entities = len(self.entity_dict)\n",
        "        self.num_relations = len(self.relation_dict)\n",
        "\n",
        "    # def _read_dict(self, file_path):\n",
        "    #     \"\"\"Read a dictionary file mapping strings to integers.\"\"\"\n",
        "    #     with open(file_path, 'r') as f:\n",
        "    #         lines = f.readlines()\n",
        "    #     return {line.split('\\t')[0]: int(line.split('\\t')[1]) for line in lines}\n",
        "\n",
        "    def _read_dict(self, file_path: str):\n",
        "        \"\"\"\n",
        "        Read entity / relation dict.\n",
        "        Format: dict({id: entity / relation})\n",
        "        \"\"\"\n",
        "\n",
        "        element_dict = {}\n",
        "        with open(file_path, 'r') as f:\n",
        "            for line in f:\n",
        "                id_, element = line.strip().split('\\t')\n",
        "                element_dict[element] = int(id_)\n",
        "\n",
        "        return element_dict\n",
        "\n",
        "    def _read_data(self, file_path):\n",
        "        \"\"\"Read triples data and map to indices.\"\"\"\n",
        "        with open(file_path, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "        triples = [line.strip().split('\\t') for line in lines]\n",
        "        return [(self.entity_dict[h], self.relation_dict[r], self.entity_dict[t]) for h, r, t in triples]\n",
        "\n",
        "    def get_edge_indices_and_types(self, data):\n",
        "        \"\"\"Convert triples into edge indices and types for PyTorch tensors.\"\"\"\n",
        "        heads, relations, tails = zip(*data)\n",
        "        edge_index = torch.tensor([heads, tails], dtype=torch.long)  # Shape: (2, num_edges)\n",
        "        edge_type = torch.tensor(relations, dtype=torch.long)  # Shape: (num_edges,)\n",
        "        return edge_index, edge_type\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gh7tKibqoAz9"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class TransE(nn.Module):\n",
        "    def __init__(self, num_entities, num_relations, embedding_dim, margin=1.0, p_norm=1):\n",
        "        \"\"\"\n",
        "        TransE model constructor.\n",
        "        Args:\n",
        "            num_entities (int): Total number of entities.\n",
        "            num_relations (int): Total number of relations.\n",
        "            embedding_dim (int): Dimensionality of embeddings.\n",
        "            margin (float): Margin for the loss function.\n",
        "            p_norm (int): Norm to use (1 for L1 norm, 2 for L2 norm).\n",
        "        \"\"\"\n",
        "        super(TransE, self).__init__()\n",
        "        self.num_entities = num_entities\n",
        "        self.num_relations = num_relations\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.margin = margin\n",
        "        self.p_norm = p_norm\n",
        "\n",
        "        # Define entity and relation embeddings\n",
        "        self.entity_embeddings = nn.Embedding(num_entities, embedding_dim)\n",
        "        self.relation_embeddings = nn.Embedding(num_relations, embedding_dim)\n",
        "\n",
        "        # Loss function\n",
        "        self.margin_ranking_loss = nn.MarginRankingLoss(margin=self.margin)\n",
        "\n",
        "        # Initialize embeddings\n",
        "        self._init_embeddings()\n",
        "\n",
        "    def _init_embeddings(self):\n",
        "        \"\"\"Initialize embeddings using Xavier uniform initialization.\"\"\"\n",
        "        nn.init.xavier_uniform_(self.entity_embeddings.weight.data)\n",
        "        nn.init.xavier_uniform_(self.relation_embeddings.weight.data)\n",
        "\n",
        "    def forward(self, head, relation, tail, mode=\"normal\"):\n",
        "        \"\"\"\n",
        "        Compute the TransE score.\n",
        "        Args:\n",
        "            head (torch.Tensor): Head entity indices.\n",
        "            relation (torch.Tensor): Relation indices.\n",
        "            tail (torch.Tensor): Tail entity indices.\n",
        "            mode (str): Evaluation mode ('normal', 'head-batch', or 'tail-batch').\n",
        "        Returns:\n",
        "            torch.Tensor: Computed scores.\n",
        "        \"\"\"\n",
        "        h = self.entity_embeddings(head)\n",
        "        r = self.relation_embeddings(relation)\n",
        "        t = self.entity_embeddings(tail)\n",
        "\n",
        "        if mode == \"normal\":\n",
        "            score = h + r - t\n",
        "        elif mode == \"head-batch\":\n",
        "            score = h.view(-1, 1, self.embedding_dim) + r - t\n",
        "        elif mode == \"tail-batch\":\n",
        "            score = h + r - t.view(-1, 1, self.embedding_dim)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported mode: {mode}\")\n",
        "\n",
        "        return -torch.norm(score, p=self.p_norm, dim=-1)\n",
        "\n",
        "    def loss(self, positive_score, negative_score):\n",
        "        \"\"\"\n",
        "        Compute the margin-based ranking loss.\n",
        "        Args:\n",
        "            positive_score (torch.Tensor): Scores for positive triples.\n",
        "            negative_score (torch.Tensor): Scores for negative triples.\n",
        "        Returns:\n",
        "            torch.Tensor: Loss value.\n",
        "        \"\"\"\n",
        "        target = torch.ones_like(positive_score)\n",
        "        return self.margin_ranking_loss(positive_score, negative_score, target)\n",
        "\n",
        "    def evaluate(self, head, relation, tail, all_entities):\n",
        "        \"\"\"\n",
        "        Evaluate the model by replacing entities in a triple.\n",
        "        Args:\n",
        "            head (torch.Tensor): Head entity indices.\n",
        "            relation (torch.Tensor): Relation indices.\n",
        "            tail (torch.Tensor): Tail entity indices.\n",
        "            all_entities (torch.Tensor): All entity indices.\n",
        "        Returns:\n",
        "            torch.Tensor: Scores for all replaced entities.\n",
        "        \"\"\"\n",
        "        batch_size = head.size(0)\n",
        "\n",
        "        # Expand for replacement\n",
        "        head_exp = head.view(-1, 1).repeat(1, all_entities.size(0))\n",
        "        relation_exp = relation.view(-1, 1).repeat(1, all_entities.size(0))\n",
        "        tail_exp = tail.view(-1, 1).repeat(1, all_entities.size(0))\n",
        "\n",
        "        # Flatten for embedding lookup\n",
        "        head_flat = head_exp.view(-1)\n",
        "        relation_flat = relation_exp.view(-1)\n",
        "        tail_flat = all_entities.repeat(batch_size)\n",
        "\n",
        "        # Compute scores\n",
        "        scores = self.forward(head_flat, relation_flat, tail_flat, mode=\"normal\")\n",
        "        return scores.view(batch_size, -1)\n"
      ],
      "metadata": {
        "id": "hXL-OrSDiAQG"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXiKs2dKoAz-"
      },
      "source": [
        "# Train Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-VlS8124rZw"
      },
      "source": [
        "## Model: TransEE\n",
        "**Embeddings:**\n",
        "Each entity and relation is represented as a vector in a high-dimensional space.\n",
        "The embeddings are initialized randomly and updated during training.\n",
        "**Distance Metric:**\n",
        "TransE predicts relationships by minimizing the distance between embeddings of head + relation - tail.\n",
        "A lower distance indicates a more likely relationship."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model TransE"
      ],
      "metadata": {
        "id": "k8Iy-EH0hgSX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, optimizer, train_loader, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        batch_h, batch_r, batch_t, batch_neg_h, batch_neg_t = [b.to(device) for b in batch]\n",
        "\n",
        "        # Positive and negative scores\n",
        "        positive_score = model(batch_h, batch_r, batch_t)\n",
        "        negative_score_h = model(batch_neg_h, batch_r, batch_t)\n",
        "        negative_score_t = model(batch_h, batch_r, batch_neg_t)\n",
        "\n",
        "        # Combine negative scores and reshape to match positive score size\n",
        "        negative_score = torch.cat([negative_score_h, negative_score_t], dim=0)\n",
        "\n",
        "        # Reshape negative_score to match the size of positive_score\n",
        "        negative_score = negative_score.view(positive_score.shape[0], -1)\n",
        "        # Calculate loss for each negative sample type (head/tail corruption) separately\n",
        "        loss_h = model.loss(positive_score, negative_score_h)\n",
        "        loss_t = model.loss(positive_score, negative_score_t)\n",
        "\n",
        "        # Average the losses to get the total loss\n",
        "        loss = (loss_h + loss_t) / 2\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(train_loader)"
      ],
      "metadata": {
        "id": "Sskt0BzNh0LO"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "AXyRx09YhnYW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyUVJhNroAz-"
      },
      "source": [
        "# Evaluate Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tzLhqtE4XK_"
      },
      "source": [
        "## Prediction:\n",
        "After training, the model can predict missing relationships by ranking possible tail entities for a given (head, relation, ?).\n",
        "Example Query:\n",
        "Input: (Steve Jobs, FounderOf, ?)\n",
        "Output: Apple (highest-ranked entity)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, eval_loader, all_entities, device, batch_size=64):  # Reduced batch size\n",
        "    model.eval()\n",
        "    mrr, mr, hits_at_10, hits_at_3, hits_at_1 = 0, 0, 0, 0, 0\n",
        "    num_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in eval_loader:\n",
        "            batch_h, batch_r, batch_t = [b.to(device) for b in batch]\n",
        "\n",
        "            # Split the evaluation into smaller chunks to reduce memory usage\n",
        "            for i in range(0, batch_h.shape[0], batch_size):\n",
        "                chunk_h = batch_h[i:i + batch_size]\n",
        "                chunk_r = batch_r[i:i + batch_size]\n",
        "                chunk_t = batch_t[i:i + batch_size]  # Get the corresponding chunk of batch_t\n",
        "\n",
        "                scores = model.evaluate(chunk_h, chunk_r, chunk_t, all_entities)\n",
        "\n",
        "                # Compute rankings using chunk_t\n",
        "                ranks = (scores.argsort(dim=1, descending=True).eq(chunk_t.view(-1, 1))).nonzero(as_tuple=True)[1] + 1\n",
        "\n",
        "                # Metrics\n",
        "                mrr += (1.0 / ranks.float()).sum().item()\n",
        "                mr += ranks.float().sum().item()\n",
        "                hits_at_10 += (ranks <= 10).float().sum().item()\n",
        "                hits_at_3 += (ranks <= 3).float().sum().item()\n",
        "                hits_at_1 += (ranks == 1).float().sum().item()\n",
        "\n",
        "                num_samples += chunk_t.size(0)  # Update num_samples based on chunk size\n",
        "\n",
        "    return {\n",
        "        \"MRR\": mrr / num_samples,\n",
        "        \"MR\": mr / num_samples,\n",
        "        \"Hits@10\": hits_at_10 / num_samples,\n",
        "        \"Hits@3\": hits_at_3 / num_samples,\n",
        "        \"Hits@1\": hits_at_1 / num_samples,\n",
        "    }"
      ],
      "metadata": {
        "id": "dRxhn1CsiINN"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4a5ovUh4oAz_"
      },
      "source": [
        "# Start Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6FOxlII4jEq"
      },
      "source": [
        "## Positive Triplets:\n",
        "The dataset provides positive examples in the form of valid (head, relation, tail) triplets.\n",
        "## Negative Sampling:\n",
        "For each positive triplet, a corrupted version is generated by replacing either the head or tail with a random entity.\n",
        "## Loss Function:\n",
        "The model uses margin-based ranking loss:\n",
        "Ensures valid triplets are closer in embedding space than invalid ones by at least a predefined margin."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Last good run\n",
        "Validation score: MRR = 0.2749, MR = 164.3813, Hits@10 = 0.4441, Hits@3 = 0.2908, Hits@1 = 0.1938\n",
        "Test scores from the best model (MMR, MR, Hits@10): (0.26878729462623596, 170.3550767125965, 0.4360891234242158, 0.28647512948304504, 0.1866021694517737)"
      ],
      "metadata": {
        "id": "J0vE3IZrRh_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Define training parameters\n",
        "lr = 0.001\n",
        "use_gpu = torch.cuda.is_available()\n",
        "if use_gpu:\n",
        "    num_epochs = 190\n",
        "    valid_freq = 10\n",
        "else:\n",
        "    num_epochs = 10\n",
        "    valid_freq = 10\n",
        "\n",
        "device = torch.device('cuda' if use_gpu else 'cpu')\n",
        "\n",
        "# Load dataset using CustomDataset class\n",
        "data_path = '/content/sample_data'\n",
        "dataset = CustomDataset(data_path)\n",
        "\n",
        "# Extract edge indices and types\n",
        "train_edge_index, train_edge_type = dataset.get_edge_indices_and_types(dataset.train_data)\n",
        "valid_edge_index, valid_edge_type = dataset.get_edge_indices_and_types(dataset.valid_data)\n",
        "test_edge_index, test_edge_type = dataset.get_edge_indices_and_types(dataset.test_data)\n",
        "\n",
        "# Negative Sampling Function\n",
        "def negative_sampling(edge_index, num_entities):\n",
        "    \"\"\"\n",
        "    Generate negative samples by replacing the head or tail with a random entity.\n",
        "    Args:\n",
        "        edge_index (torch.Tensor): The edge index (head and tail indices).\n",
        "        num_entities (int): Total number of entities.\n",
        "    Returns:\n",
        "        torch.Tensor: Negative samples.\n",
        "    \"\"\"\n",
        "    num_edges = edge_index.size(1)\n",
        "    negative_samples = edge_index.clone()\n",
        "    random_entities = torch.randint(0, num_entities, (num_edges,))\n",
        "    mask = torch.rand(num_edges) > 0.5  # Randomly replace head or tail\n",
        "    negative_samples[0, mask] = random_entities[mask]  # Replace heads\n",
        "    negative_samples[1, ~mask] = random_entities[~mask]  # Replace tails\n",
        "    return negative_samples\n",
        "\n",
        "# Prepare training data\n",
        "train_heads = train_edge_index[0]\n",
        "train_tails = train_edge_index[1]\n",
        "train_relations = train_edge_type\n",
        "\n",
        "# Generate negative samples for training\n",
        "negative_samples = negative_sampling(train_edge_index, dataset.num_entities)\n",
        "\n",
        "# Create TensorDataset and DataLoader for training\n",
        "train_dataset = TensorDataset(train_heads, train_relations, train_tails,\n",
        "                               negative_samples[0], negative_samples[1])\n",
        "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
        "\n",
        "# Create DataLoader for validation\n",
        "valid_dataset = TensorDataset(valid_edge_index[0], valid_edge_type, valid_edge_index[1])\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=256, shuffle=False)\n",
        "\n",
        "# Create DataLoader for testing\n",
        "test_dataset = TensorDataset(test_edge_index[0], test_edge_type, test_edge_index[1])\n",
        "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
        "\n",
        "# Initialize the TransE model\n",
        "model = TransE(\n",
        "    num_entities=dataset.num_entities,\n",
        "    num_relations=dataset.num_relations,\n",
        "    embedding_dim=200,  # Dimensionality of embeddings\n",
        "    margin=9.0          # Margin for ranking loss\n",
        ").to(device)\n",
        "\n",
        "# Define optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "\n",
        "# Training and Validation Loop\n",
        "for epoch in range(num_epochs):\n",
        "    # Training step\n",
        "    train(\n",
        "        model=model,\n",
        "        train_loader=train_loader,\n",
        "        optimizer=optimizer,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    # Validation step\n",
        "    if (epoch + 1) % valid_freq == 0:\n",
        "        all_entities = torch.arange(dataset.num_entities, device=device)\n",
        "        val_metrics = evaluate(\n",
        "            model=model,\n",
        "            eval_loader=valid_loader,\n",
        "            all_entities=all_entities,\n",
        "            device=device\n",
        "        )\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs} - Validation Metrics: {val_metrics}\")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "all_entities = torch.arange(dataset.num_entities, device=device)\n",
        "test_metrics = evaluate(\n",
        "    model=model,\n",
        "    eval_loader=test_loader,\n",
        "    all_entities=all_entities,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "# Print test metrics\n",
        "print(\"Test Metrics:\", test_metrics)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGpAS83ZiaiS",
        "outputId": "95f74824-d0a9-4d74-e710-411809b421d3"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/190 - Validation Metrics: {'MRR': 0.18528308281029668, 'MR': 372.79669232962647, 'Hits@10': 0.32671799258625606, 'Hits@3': 0.19880239520958085, 'Hits@1': 0.11348731109210151}\n",
            "Epoch 20/190 - Validation Metrics: {'MRR': 0.18744408523455147, 'MR': 378.4536070715711, 'Hits@10': 0.3137154262902766, 'Hits@3': 0.19731964642144284, 'Hits@1': 0.12033076703735386}\n",
            "Epoch 30/190 - Validation Metrics: {'MRR': 0.189440855342233, 'MR': 381.97502138579983, 'Hits@10': 0.32859994297120043, 'Hits@3': 0.20290846877673224, 'Hits@1': 0.11833475905332193}\n",
            "Epoch 40/190 - Validation Metrics: {'MRR': 0.17984598356670622, 'MR': 380.99458226404334, 'Hits@10': 0.32848588537211293, 'Hits@3': 0.19749073282007415, 'Hits@1': 0.10287995437696036}\n",
            "Epoch 50/190 - Validation Metrics: {'MRR': 0.19152619914176425, 'MR': 384.67676076418593, 'Hits@10': 0.3291132021670944, 'Hits@3': 0.20747077274023382, 'Hits@1': 0.11873396065012831}\n",
            "Epoch 60/190 - Validation Metrics: {'MRR': 0.19622006235484354, 'MR': 383.41345879669234, 'Hits@10': 0.3401767892785857, 'Hits@3': 0.20958083832335328, 'Hits@1': 0.12443684060450527}\n",
            "Epoch 70/190 - Validation Metrics: {'MRR': 0.19548438822471895, 'MR': 378.84625035643, 'Hits@10': 0.3268890789848874, 'Hits@3': 0.20165383518676933, 'Hits@1': 0.13059595095523238}\n",
            "Epoch 80/190 - Validation Metrics: {'MRR': 0.18485994466798475, 'MR': 385.3528371827773, 'Hits@10': 0.3307670373538637, 'Hits@3': 0.19851725121186198, 'Hits@1': 0.11160536070715711}\n",
            "Epoch 90/190 - Validation Metrics: {'MRR': 0.1884794863126269, 'MR': 379.48366124893073, 'Hits@10': 0.3371542629027659, 'Hits@3': 0.20815511833475905, 'Hits@1': 0.11132021670943827}\n",
            "Epoch 100/190 - Validation Metrics: {'MRR': 0.19841209427393294, 'MR': 378.81026518391786, 'Hits@10': 0.3363558597091531, 'Hits@3': 0.2118049615055603, 'Hits@1': 0.1270031365839749}\n",
            "Epoch 110/190 - Validation Metrics: {'MRR': 0.18496077659635216, 'MR': 376.69347020245226, 'Hits@10': 0.3311662389506701, 'Hits@3': 0.20034217279726263, 'Hits@1': 0.11052181351582549}\n",
            "Epoch 120/190 - Validation Metrics: {'MRR': 0.20106186830049094, 'MR': 379.921129170231, 'Hits@10': 0.34063301967493587, 'Hits@3': 0.2212147134302823, 'Hits@1': 0.12802965497576277}\n",
            "Epoch 130/190 - Validation Metrics: {'MRR': 0.19219284897894814, 'MR': 376.3331622469347, 'Hits@10': 0.3409751924721985, 'Hits@3': 0.20667236954662105, 'Hits@1': 0.11827773025377816}\n",
            "Epoch 140/190 - Validation Metrics: {'MRR': 0.19145156008108818, 'MR': 378.91120615911035, 'Hits@10': 0.3431422868548617, 'Hits@3': 0.21083547191331622, 'Hits@1': 0.11365839749073282}\n",
            "Epoch 150/190 - Validation Metrics: {'MRR': 0.18668037435761672, 'MR': 379.9963501568292, 'Hits@10': 0.34924436840604506, 'Hits@3': 0.20701454234388367, 'Hits@1': 0.10533219275734246}\n",
            "Epoch 160/190 - Validation Metrics: {'MRR': 0.2017843004166315, 'MR': 379.3063016823496, 'Hits@10': 0.3463358996293128, 'Hits@3': 0.21653835186769319, 'Hits@1': 0.1283147989734816}\n",
            "Epoch 170/190 - Validation Metrics: {'MRR': 0.19086623503198508, 'MR': 377.36698032506416, 'Hits@10': 0.34644995722840033, 'Hits@3': 0.21214713430282292, 'Hits@1': 0.11114913031080696}\n",
            "Epoch 180/190 - Validation Metrics: {'MRR': 0.18405647209848405, 'MR': 375.9933276304534, 'Hits@10': 0.3486740804106074, 'Hits@3': 0.19988594240091245, 'Hits@1': 0.10470487596236099}\n",
            "Epoch 190/190 - Validation Metrics: {'MRR': 0.1911275137582327, 'MR': 377.74627887082977, 'Hits@10': 0.3446820644425435, 'Hits@3': 0.20387795836897632, 'Hits@1': 0.11645280866837752}\n",
            "Test Metrics: {'MRR': 0.18416362536637348, 'MR': 391.55443174044757, 'Hits@10': 0.3410045929834848, 'Hits@3': 0.19974592006254274, 'Hits@1': 0.10783738884002736}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "\n",
        "# # Check if CUDA is available\n",
        "# if torch.cuda.is_available():\n",
        "#     # Get the device properties\n",
        "#     device_properties = torch.cuda.get_device_properties(0)  # 0 for the first GPU\n",
        "\n",
        "#     # Get total memory in bytes\n",
        "#     total_memory = device_properties.total_memory\n",
        "\n",
        "#     # Get allocated memory in bytes\n",
        "#     allocated_memory = torch.cuda.memory_allocated(0)\n",
        "\n",
        "#     # Get reserved memory in bytes\n",
        "#     reserved_memory = torch.cuda.memory_reserved(0)\n",
        "\n",
        "#     # Calculate free memory in bytes\n",
        "#     free_memory = total_memory - allocated_memory - reserved_memory\n",
        "\n",
        "#     # Print the results in GB\n",
        "#     print(f\"Total CUDA memory: {total_memory / (1024**3):.2f} GB\")\n",
        "#     print(f\"Allocated CUDA memory: {allocated_memory / (1024**3):.2f} GB\")\n",
        "#     print(f\"Reserved CUDA memory: {reserved_memory / (1024**3):.2f} GB\")\n",
        "#     print(f\"Free CUDA memory: {free_memory / (1024**3):.2f} GB\")\n",
        "\n",
        "# else:\n",
        "#     print(\"CUDA is not available.\")"
      ],
      "metadata": {
        "id": "I0CTDsvPvsCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vs_oJCzJ3am6"
      },
      "source": [
        "# Example Workflow:\n",
        "## Input:\n",
        "\n",
        "**Dataset**: (Barack Obama, PresidentOf, United States), (Elon Musk, FounderOf, Tesla).\n",
        "**Embedding Initialization**:\n",
        "\n",
        "**Entities**: Barack Obama, United States, Elon Musk, Tesla.\n",
        "**Relations**: PresidentOf, FounderOf.\n",
        "**Training:**\n",
        "\n",
        "**Positive Triplets**: (Barack Obama, PresidentOf, United States).\n",
        "**Negative Sampling**: (Barack Obama, PresidentOf, RandomEntity).\n",
        "Evaluation:\n",
        "\n",
        "Metrics like **MRR, MR,** and **Hits@10** are computed during validation to measure the modelâ€™s performance.\n",
        "Prediction:\n",
        "\n",
        "**Query**: *(Elon Musk, FounderOf, ?)*\n",
        "**Prediction**: Tesla (most likely tail).\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}