{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmSOksvuoAz3"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MRLotX9cpCWr"
      },
      "outputs": [],
      "source": [
        "# whether you are using a GPU to run this Colab\n",
        "use_gpu = True\n",
        "# whether you are using a custom GCE env to run the Colab (uses different CUDA)\n",
        "custom_GCE_env = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFbWsOOboAz5",
        "outputId": "ba39e401-d08f-4d69-b54e-9bc9f253ef0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.59.4)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.10.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n"
          ]
        }
      ],
      "source": [
        "%pip install openai\n",
        "%pip install python-dotenv\n",
        "# %pip install torch-geometric\n",
        "# %pip install torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
        "# %pip install torch-sparse -f https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "import re\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "# from torch_geometric.data import InMemoryDataset, DataLoader\n",
        "# import torch_geometric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uj9IXX0LoAz8"
      },
      "source": [
        "# Data Preparation and Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Ktbb1Ambdnxv"
      },
      "outputs": [],
      "source": [
        "class CustomDataset:\n",
        "    def __init__(self, data_path: str):\n",
        "        \"\"\"\n",
        "        Custom Dataset class for loading and processing data without PyTorch Geometric.\n",
        "\n",
        "        Args:\n",
        "            data_path (str): Path to the dataset directory.\n",
        "        \"\"\"\n",
        "\n",
        "        #data_path = '/Users/abhi/GitHUB/FederatedRAG1/DataSets/FB15k-237'\n",
        "        # Paths to files\n",
        "        self.entity_dict_path = os.path.join(data_path, 'entities.dict')\n",
        "        self.relation_dict_path = os.path.join(data_path, 'relations.dict')\n",
        "        self.train_data_path = os.path.join(data_path, 'train.txt')\n",
        "        self.valid_data_path = os.path.join(data_path, 'valid.txt')\n",
        "        self.test_data_path = os.path.join(data_path, 'test.txt')\n",
        "\n",
        "        # Load dictionaries and datasets\n",
        "        self.entity_dict = self._read_dict(self.entity_dict_path)\n",
        "        self.relation_dict = self._read_dict(self.relation_dict_path)\n",
        "\n",
        "        self.train_data = self._read_data(self.train_data_path)\n",
        "        self.valid_data = self._read_data(self.valid_data_path)\n",
        "        self.test_data = self._read_data(self.test_data_path)\n",
        "\n",
        "        self.num_entities = len(self.entity_dict)\n",
        "        self.num_relations = len(self.relation_dict)\n",
        "\n",
        "    # def _read_dict(self, file_path):\n",
        "    #     \"\"\"Read a dictionary file mapping strings to integers.\"\"\"\n",
        "    #     with open(file_path, 'r') as f:\n",
        "    #         lines = f.readlines()\n",
        "    #     return {line.split('\\t')[0]: int(line.split('\\t')[1]) for line in lines}\n",
        "\n",
        "    def _read_dict(self, file_path: str):\n",
        "        \"\"\"\n",
        "        Read entity / relation dict.\n",
        "        Format: dict({id: entity / relation})\n",
        "        \"\"\"\n",
        "\n",
        "        element_dict = {}\n",
        "        with open(file_path, 'r') as f:\n",
        "            for line in f:\n",
        "                id_, element = line.strip().split('\\t')\n",
        "                element_dict[element] = int(id_)\n",
        "\n",
        "        return element_dict\n",
        "\n",
        "    def _read_data(self, file_path):\n",
        "        \"\"\"Read triples data and map to indices.\"\"\"\n",
        "        with open(file_path, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "        triples = [line.strip().split('\\t') for line in lines]\n",
        "        return [(self.entity_dict[h], self.relation_dict[r], self.entity_dict[t]) for h, r, t in triples]\n",
        "\n",
        "    def get_edge_indices_and_types(self, data):\n",
        "        \"\"\"Convert triples into edge indices and types for PyTorch tensors.\"\"\"\n",
        "        heads, relations, tails = zip(*data)\n",
        "        edge_index = torch.tensor([heads, tails], dtype=torch.long)  # Shape: (2, num_edges)\n",
        "        edge_type = torch.tensor(relations, dtype=torch.long)  # Shape: (num_edges,)\n",
        "        return edge_index, edge_type\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gh7tKibqoAz9"
      },
      "source": [
        "# TransGPT Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dt4KLlz5oAz9"
      },
      "outputs": [],
      "source": [
        "class TransEEnhanced(nn.Module):\n",
        "    def __init__(self, num_entities, num_relations, embedding_dim, margin, distance_metric=2, # 1 for L1 and 2 for L2\n",
        "                 gamma=10.0, phase_weight=1.0, modulus_weight=4.0, epsilon=1.0,reg_coeff=1e-4):\n",
        "        super(TransEEnhanced, self).__init__()\n",
        "\n",
        "        # Basic TransE embeddings\n",
        "        self.entity_modulus = nn.Embedding(num_entities, embedding_dim)\n",
        "        self.entity_phase = nn.Embedding(num_entities, embedding_dim)\n",
        "        self.relation_modulus = nn.Embedding(num_relations, embedding_dim)\n",
        "        self.relation_phase = nn.Embedding(num_relations, embedding_dim)\n",
        "\n",
        "        # Margin and distance settings\n",
        "        self.margin = margin\n",
        "        self.distance_metric = distance_metric\n",
        "\n",
        "\n",
        "        # Hyperbolic and scaling settings\n",
        "        self.gamma = nn.Parameter(torch.Tensor([gamma]), requires_grad=False)\n",
        "        self.embedding_range = nn.Parameter(\n",
        "            torch.Tensor([(self.gamma.item() + epsilon) / embedding_dim]), requires_grad=False\n",
        "        )\n",
        "\n",
        "        # Weights for phase and modulus\n",
        "        self.phase_weight = phase_weight\n",
        "        self.modulus_weight = modulus_weight\n",
        "        self.reg_coeff = reg_coeff\n",
        "\n",
        "        # Initialization\n",
        "        nn.init.uniform_(self.entity_modulus.weight, a=-self.embedding_range.item(), b=self.embedding_range.item())\n",
        "        nn.init.uniform_(self.entity_phase.weight, a=-np.pi, b=np.pi)\n",
        "        nn.init.uniform_(self.relation_modulus.weight, a=-self.embedding_range.item(), b=self.embedding_range.item())\n",
        "        nn.init.uniform_(self.relation_phase.weight, a=-np.pi, b=np.pi)\n",
        "\n",
        "    def forward(self, head, relation, tail):\n",
        "        # h_mod = self.entity_modulus(head)\n",
        "        # h_phase = self.entity_phase(head)\n",
        "        # r_mod = self.relation_modulus(relation)\n",
        "        # r_phase = self.relation_phase(relation)\n",
        "        # t_mod = self.entity_modulus(tail)\n",
        "        # t_phase = self.entity_phase(tail)\n",
        "\n",
        "        # Move input tensors to the device\n",
        "        head = head.to(self.entity_modulus.weight.device)\n",
        "        relation = relation.to(self.relation_modulus.weight.device)\n",
        "        tail = tail.to(self.entity_modulus.weight.device)\n",
        "\n",
        "        h_mod = self.entity_modulus(head)\n",
        "        h_phase = self.entity_phase(head)\n",
        "        r_mod = self.relation_modulus(relation)\n",
        "        r_phase = self.relation_phase(relation)\n",
        "        t_mod = self.entity_modulus(tail)\n",
        "        t_phase = self.entity_phase(tail)\n",
        "\n",
        "        # Modulus scoring: hyperbolic-inspired adjustment\n",
        "        modulus_score = torch.norm(h_mod * r_mod - t_mod, p=self.distance_metric, dim=-1)\n",
        "\n",
        "        # Phase scoring: advanced angular consistency\n",
        "        phase_diff = torch.abs(torch.sin((h_phase + r_phase - t_phase) / 2))\n",
        "        phase_score = torch.sum(phase_diff, dim=-1)\n",
        "\n",
        "        # Weighted combined score\n",
        "        score = self.modulus_weight * modulus_score + self.phase_weight * phase_score\n",
        "        return score\n",
        "\n",
        "    def compute_loss(self, positive_score, negative_score):\n",
        "        # Margin-based ranking loss\n",
        "        base_loss = F.relu(self.margin + positive_score - negative_score)\n",
        "\n",
        "        # Regularization terms for Elastic modulus and phase (combining L1 and L2)\n",
        "        modulus_regularization_L1 = torch.sum(torch.norm(self.entity_modulus.weight, p=1, dim=-1))\n",
        "        modulus_regularization_L2 = torch.sum(torch.norm(self.entity_modulus.weight, p=2, dim=-1))\n",
        "        phase_regularization_L1 = torch.sum(torch.norm(self.entity_phase.weight, p=1, dim=-1))\n",
        "        phase_regularization_L2 = torch.sum(torch.norm(self.entity_phase.weight, p=2, dim=-1))\n",
        "\n",
        "        # Total loss with combined regularization\n",
        "        # Introduce alpha to control the mix between L1 and L2\n",
        "        alpha = 0.5  # Example value, you can adjust this\n",
        "        total_loss = base_loss.mean() + self.reg_coeff * (\n",
        "            alpha * (modulus_regularization_L1 + phase_regularization_L1) +\n",
        "            (1 - alpha) * (modulus_regularization_L2 + phase_regularization_L2)\n",
        "    )\n",
        "\n",
        "\n",
        "        # # Regularization terms for modulus and phase\n",
        "        # modulus_regularization = torch.sum(torch.norm(self.entity_modulus.weight, p=self.distance_metric, dim=-1))\n",
        "        # phase_regularization = torch.sum(torch.norm(self.entity_phase.weight, p=self.distance_metric, dim=-1))\n",
        "\n",
        "        # # Total loss with regularization\n",
        "        # # total_loss = base_loss.mean() + 1e-5 * (modulus_regularization + phase_regularization)\n",
        "        # # total_loss = base_loss.mean() + 1e-3 * (modulus_regularization + phase_regularization)\n",
        "        # total_loss = base_loss.mean() + 1e-4 * (modulus_regularization + phase_regularization)\n",
        "        # # total_loss = base_loss.mean() + 1e-2 * (modulus_regularization + phase_regularization)\n",
        "        return total_loss\n",
        "\n",
        "# Helper function to create corrupted edges\n",
        "def create_corrupted_edge_index(edge_index, edge_type, num_entities,negative_rate =50):\n",
        "      \"\"\"\n",
        "    Creates corrupted edge indices for negative sampling.\n",
        "\n",
        "    Args:\n",
        "        edge_index (torch.Tensor): The original edge indices.\n",
        "        edge_type (torch.Tensor): The edge types.\n",
        "        num_entities (int): The total number of entities.\n",
        "        negative_rate (int, optional): The number of negative samples per positive sample. Defaults to 1.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: The corrupted edge indices.\n",
        "    \"\"\"\n",
        "\n",
        "    # Repeat the original edge indices based on the negative rate\n",
        "      num_positive_edges = edge_index.shape[1]\n",
        "      repeated_edge_index = edge_index.repeat(1, negative_rate)\n",
        "      repeated_edge_type = edge_type.repeat(negative_rate)\n",
        "\n",
        "    # Create corrupted edges\n",
        "      corrupt_head_or_tail = torch.randint(high=2, size=(num_positive_edges * negative_rate,),\n",
        "                                         device=edge_index.device)\n",
        "      random_entities = torch.randint(high=num_entities,\n",
        "                                     size=(num_positive_edges * negative_rate,), device=edge_index.device)\n",
        "\n",
        "    # Corrupt either head or tail based on corrupt_head_or_tail\n",
        "      heads = torch.where(corrupt_head_or_tail == 1, random_entities,\n",
        "                          repeated_edge_index[0, :])\n",
        "      tails = torch.where(corrupt_head_or_tail == 0, random_entities,\n",
        "                          repeated_edge_index[1, :])\n",
        "\n",
        "      return torch.stack([heads, tails], dim=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXiKs2dKoAz-"
      },
      "source": [
        "# Train Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-VlS8124rZw"
      },
      "source": [
        "## Model: TransE\n",
        "**Embeddings:**\n",
        "Each entity and relation is represented as a vector in a high-dimensional space.\n",
        "The embeddings are initialized randomly and updated during training.\n",
        "**Distance Metric:**\n",
        "TransE predicts relationships by minimizing the distance between embeddings of head + relation - tail.\n",
        "A lower distance indicates a more likely relationship."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAtTXKqh5Mdo"
      },
      "source": [
        "## How Is the LLM Used?\n",
        "1. Prediction Refinement\n",
        "After the TransE model predicts relationships (e.g., a tail entity for a given head and relation), these predictions are passed to the LLM.\n",
        "The LLM evaluates the predictions, identifies errors, and suggests corrections or more plausible results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "vscode": {
          "languageId": "ruby"
        },
        "id": "rnLn4HqKdnxx"
      },
      "outputs": [],
      "source": [
        "def train(model, data, optimizer, device, entity_dict, relation_dict, epochs=50, batch_size=124, valid_freq=5):\n",
        "    train_edge_index = data.train_edge_index.to(device)\n",
        "    train_edge_type = data.train_edge_type.to(device)\n",
        "    valid_edge_index = data.valid_edge_index.to(device)\n",
        "    valid_edge_type = data.valid_edge_type.to(device)\n",
        "\n",
        "    best_valid_score = 0\n",
        "    valid_scores = None\n",
        "    test_scores = None\n",
        "    metrics = None\n",
        "\n",
        "    lr_scheduler = ReduceLROnPlateau(optimizer, patience=10, factor=0.5) # Initialize scheduler\n",
        "\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "\n",
        "        # Normalize entity embeddings (modulus only)\n",
        "        entities_modulus_norm = torch.norm(model.entity_modulus.weight.data, dim=1, keepdim=True)\n",
        "        model.entity_modulus.weight.data = model.entity_modulus.weight.data / entities_modulus_norm\n",
        "\n",
        "        # Shuffle the training data\n",
        "        num_triples = train_edge_type.size(0)\n",
        "        shuffled_indices = torch.randperm(num_triples)\n",
        "        shuffled_edge_index = train_edge_index[:, shuffled_indices]\n",
        "        shuffled_edge_type = train_edge_type[shuffled_indices]\n",
        "\n",
        "        # negative_edge_index = create_corrupted_edge_index(shuffled_edge_index, shuffled_edge_type, data.num_entities)\n",
        "        negative_edge_index = create_corrupted_edge_index(shuffled_edge_index, shuffled_edge_type, data.num_entities, negative_rate=20)  # Generate 10 negative samples per positive sample\n",
        "\n",
        "        total_loss = 0\n",
        "        total_size = 0\n",
        "\n",
        "        for batch_start in range(0, num_triples, batch_size):\n",
        "            batch_end = min(batch_start + batch_size, num_triples)\n",
        "            batch_edge_index = shuffled_edge_index[:, batch_start:batch_end]\n",
        "            batch_negative_edge_index = negative_edge_index[:, batch_start:batch_end]\n",
        "            batch_edge_type = shuffled_edge_type[batch_start:batch_end]\n",
        "\n",
        "\n",
        "             # Move batch data to the device\n",
        "            batch_edge_index = batch_edge_index.to(device)\n",
        "            batch_negative_edge_index = batch_negative_edge_index.to(device)\n",
        "            batch_edge_type = batch_edge_type.to(device)\n",
        "\n",
        "            # Compute positive and negative scores for TransEEnhanced\n",
        "            positive_score = model(batch_edge_index[0], batch_edge_type, batch_edge_index[1])\n",
        "            negative_score = model(batch_negative_edge_index[0], batch_edge_type, batch_negative_edge_index[1])\n",
        "\n",
        "            # Compute loss using TransEEnhanced's loss function\n",
        "            loss = model.compute_loss(positive_score, negative_score)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item() * (batch_end - batch_start)\n",
        "            total_size += batch_end - batch_start\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / total_size:.4f}\")\n",
        "\n",
        "        # Validation at regular intervals\n",
        "        if (epoch + 1) % valid_freq == 0:\n",
        "            # mrr_score, mr_score, hits_at_10 = evaluate_model(\n",
        "                # Introduced the Hit@1,3\n",
        "            mrr_score, mr_score, hits_at_10, hits_at_3, hits_at_1 = evaluate_model(\n",
        "                model, valid_edge_index, valid_edge_type, data.num_entities, device\n",
        "            )\n",
        "\n",
        "            # introduced validation loss\n",
        "            valid_loss = evaluate_loss(model, valid_edge_index, valid_edge_type, device)\n",
        "            lr_scheduler.step(valid_loss)\n",
        "\n",
        "            # print(f\"Validation score: MRR = {mrr_score:.4f}, MR = {mr_score:.4f}, Hits@10 = {hits_at_10:.4f}\")\n",
        "            print(f\"Validation score: MRR = {mrr_score:.4f}, MR = {mr_score:.4f}, Hits@10 = {hits_at_10:.4f}, Hits@3 = {hits_at_3:.4f}, Hits@1 = {hits_at_1:.4f}\")\n",
        "            # Track best validation score\n",
        "            if mrr_score > best_valid_score:\n",
        "                best_valid_score = mrr_score\n",
        "                # test_mrr, test_mr, test_hits_at_10 = evaluate_model(\n",
        "                test_mrr, test_mr, test_hits_at_10,test_hits_at_3,test_hits_at_1 = evaluate_model(\n",
        "                    model, data.test_edge_index.to(device), data.test_edge_type.to(device), data.num_entities, device\n",
        "                )\n",
        "                test_scores = (test_mrr, test_mr, test_hits_at_10,test_hits_at_3,test_hits_at_1)\n",
        "\n",
        "    metrics = {\n",
        "        'MRR': test_mrr,\n",
        "        'MR': test_mr,\n",
        "        'Hits@10': test_hits_at_10,\n",
        "        'Hits@3': test_hits_at_3,\n",
        "        'Hits@1': test_hits_at_1\n",
        "    }\n",
        "    print(f\"Test scores from the best model (MMR, MR, Hits@10): {test_scores}\")\n",
        "    # print(f\"Metrics: {metrics}\")\n",
        "    return metrics\n",
        "\n",
        "\n",
        "# Helper function to evaluate loss on validation set\n",
        "def evaluate_loss(model, edge_index, edge_type, device):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        positive_score = model(edge_index[0].to(device), edge_type.to(device), edge_index[1].to(device))\n",
        "        loss = positive_score.mean()  # Or any other relevant loss calculation\n",
        "    return loss.item()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyUVJhNroAz-"
      },
      "source": [
        "# Evaluate Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tzLhqtE4XK_"
      },
      "source": [
        "## Prediction:\n",
        "After training, the model can predict missing relationships by ranking possible tail entities for a given (head, relation, ?).\n",
        "Example Query:\n",
        "Input: (Steve Jobs, FounderOf, ?)\n",
        "Output: Apple (highest-ranked entity)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, edge_index, edge_type, num_entities, device, eval_batch_size=32):\n",
        "    model.eval()\n",
        "    num_triples = edge_type.size(0)\n",
        "    mrr_score = 0\n",
        "    mr_score = 0\n",
        "    hits_at_10 = 0\n",
        "    hits_at_3 = 0\n",
        "    hits_at_1 = 0\n",
        "    num_predictions = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx in range(math.ceil(num_triples / eval_batch_size)):\n",
        "            batch_start = batch_idx * eval_batch_size\n",
        "            batch_end = min((batch_idx + 1) * eval_batch_size, num_triples)\n",
        "            # batch_edge_index = edge_index[:, batch_start:batch_end]\n",
        "            # batch_edge_type = edge_type[batch_start:batch_end]\n",
        "            # batch_size = batch_edge_type.size(0)\n",
        "\n",
        "            # # all_entities = torch.arange(num_entities, device=device).unsqueeze(0).repeat(batch_size, 1)\n",
        "            # # head_repeated = batch_edge_index[0, :].reshape(-1, 1).repeat(1, num_entities)\n",
        "            # # relation_repeated = batch_edge_type.reshape(-1, 1).repeat(1, num_entities)\n",
        "\n",
        "            # # head_squeezed = head_repeated.reshape(-1)\n",
        "            # # relation_squeezed = relation_repeated.reshape(-1)\n",
        "            # # all_entities_squeezed = all_entities.reshape(-1)\n",
        "\n",
        "            # # entity_index_replaced_tail = torch.stack((head_squeezed, all_entities_squeezed))\n",
        "            # # predictions = model(entity_index_replaced_tail[0], relation_squeezed, entity_index_replaced_tail[1])\n",
        "\n",
        "            # all_entities = torch.arange(num_entities, device=device).unsqueeze(0).repeat(batch_size, 1)\n",
        "            # head_repeated = batch_edge_index[0, :].reshape(-1, 1).repeat(1, num_entities)\n",
        "            # relation_repeated = batch_edge_type.reshape(-1, 1).repeat(1, num_entities)\n",
        "\n",
        "            # Move batch data to the device immediately after slicing\n",
        "            batch_edge_index = edge_index[:, batch_start:batch_end].to(device)\n",
        "            batch_edge_type = edge_type[batch_start:batch_end].to(device)\n",
        "            batch_size = batch_edge_type.size(0)\n",
        "\n",
        "            all_entities = torch.arange(num_entities, device=device).unsqueeze(0).repeat(batch_size, 1)\n",
        "            head_repeated = batch_edge_index[0, :].reshape(-1, 1).repeat(1, num_entities)\n",
        "            relation_repeated = batch_edge_type.reshape(-1, 1).repeat(1, num_entities)\n",
        "\n",
        "\n",
        "            # Move tensors to the device\n",
        "            head_repeated = head_repeated.to(device)\n",
        "            relation_repeated = relation_repeated.to(device)\n",
        "\n",
        "            head_squeezed = head_repeated.reshape(-1)\n",
        "            relation_squeezed = relation_repeated.reshape(-1)\n",
        "            all_entities_squeezed = all_entities.reshape(-1)\n",
        "\n",
        "            entity_index_replaced_tail = torch.stack((head_squeezed, all_entities_squeezed))\n",
        "            predictions = model(entity_index_replaced_tail[0], relation_squeezed, entity_index_replaced_tail[1])\n",
        "\n",
        "            predictions = predictions.reshape(batch_size, -1)\n",
        "            gt = batch_edge_index[1, :].reshape(-1, 1)\n",
        "\n",
        "            mrr_score += mrr(predictions, gt)\n",
        "            mr_score += mr(predictions, gt)\n",
        "            hits_at_10 += hit_at_k(predictions, gt, device=device, k=10)\n",
        "            hits_at_3 += hit_at_k(predictions, gt, device=device, k=3)\n",
        "            hits_at_1 += hit_at_k(predictions, gt, device=device, k=1)\n",
        "            num_predictions += batch_size\n",
        "\n",
        "    mrr_score = mrr_score / num_predictions\n",
        "    mr_score = mr_score / num_predictions\n",
        "    hits_at_10 = hits_at_10 / num_predictions\n",
        "    hits_at_3 = hits_at_3 / num_predictions\n",
        "    hits_at_1 = hits_at_1 / num_predictions\n",
        "    return mrr_score, mr_score, hits_at_10, hits_at_3, hits_at_1\n",
        "\n",
        "\n",
        "# Metric Functions\n",
        "def mrr(predictions, gt):\n",
        "  # Move both tensors to the same device\n",
        "    predictions = predictions.to(gt.device)\n",
        "    indices = predictions.argsort()\n",
        "    return (1.0 / (indices == gt).nonzero()[:, 1].float().add(1.0)).sum().item()\n",
        "\n",
        "def mr(predictions, gt):\n",
        "  # Move both tensors to the same device\n",
        "    predictions = predictions.to(gt.device)\n",
        "    indices = predictions.argsort()\n",
        "    return ((indices == gt).nonzero()[:, 1].float().add(1.0)).sum().item()\n",
        "\n",
        "def hit_at_k(predictions, gt, device, k=10):\n",
        "  # Move both tensors to the same device\n",
        "    predictions = predictions.to(gt.device)\n",
        "    # Generalized Hits@k calculation\n",
        "    zero_tensor = torch.tensor([0], device=gt.device)\n",
        "    one_tensor = torch.tensor([1], device=gt.device)\n",
        "    _, indices = predictions.topk(k=k, largest=False)\n",
        "    return torch.where(indices == gt, one_tensor, zero_tensor).sum().item()\n"
      ],
      "metadata": {
        "id": "umUkkfaT9uVb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4a5ovUh4oAz_"
      },
      "source": [
        "# Start Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6FOxlII4jEq"
      },
      "source": [
        "## Positive Triplets:\n",
        "The dataset provides positive examples in the form of valid (head, relation, tail) triplets.\n",
        "## Negative Sampling:\n",
        "For each positive triplet, a corrupted version is generated by replacing either the head or tail with a random entity.\n",
        "## Loss Function:\n",
        "The model uses margin-based ranking loss:\n",
        "Ensures valid triplets are closer in embedding space than invalid ones by at least a predefined margin."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grid Search"
      ],
      "metadata": {
        "id": "RUsI1a-Sx3yU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import itertools\n",
        "\n",
        "\n",
        "# use_gpu = torch.cuda.is_available()\n",
        "# if use_gpu:\n",
        "#     epochs = 10 #80\n",
        "#     valid_freq = 10\n",
        "# else:\n",
        "#     epochs = 10\n",
        "#     valid_freq = 10\n",
        "\n",
        "# device = torch.device('cuda' if use_gpu else 'cpu')\n",
        "\n",
        "# metrics = None\n",
        "# # Load dataset using CustomDataset class\n",
        "# data_path = '/content/sample_data'\n",
        "# dataset = CustomDataset(data_path)\n",
        "# data = dataset\n",
        "\n",
        "# # Extract edge indices and types\n",
        "# train_edge_index, train_edge_type = dataset.get_edge_indices_and_types(dataset.train_data)\n",
        "# valid_edge_index, valid_edge_type = dataset.get_edge_indices_and_types(dataset.valid_data)\n",
        "# test_edge_index, test_edge_type = dataset.get_edge_indices_and_types(dataset.test_data)\n",
        "\n",
        "# # Define the hyperparameter grid\n",
        "# param_grid = {\n",
        "#     \"embedding_dim\": [128, 256, 512],\n",
        "#     \"learning_rate\": [0.001, 0.005, 0.01],\n",
        "#     \"margin\": [5.0, 9.0, 12.0],\n",
        "#     \"batch_size\": [512, 1024],\n",
        "#     \"phase_weight\": [0.5, 1.0],\n",
        "#     \"modulus_weight\": [1.0, 2.0],\n",
        "#     \"reg_coeff\": [1e-3, 1e-4, 1e-5],\n",
        "#     \"distance_metric\": [1, 2],  # 1 for L1 and 2 for L2\n",
        "#     \"epochs\":[100]\n",
        "# }\n",
        "\n",
        "\n",
        "# # Generate all combinations of hyperparameters\n",
        "# keys, values = zip(*param_grid.items())\n",
        "# param_combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
        "\n",
        "# # Placeholder for the best configuration and its performance\n",
        "# best_config = None\n",
        "# best_mrr = -float('inf')\n",
        "\n",
        "# # Iterate through each combination of hyperparameters\n",
        "# for config in param_combinations:\n",
        "#     print(f\"Testing configuration: {config}\")\n",
        "\n",
        "#     # Initialize the model with the current hyperparameter configuration\n",
        "#     model = TransEEnhanced(\n",
        "#         num_entities=data.num_entities,\n",
        "#         num_relations=data.num_relations,\n",
        "#         embedding_dim=config['embedding_dim'],\n",
        "#         margin=config['margin'],\n",
        "#         phase_weight=config['phase_weight'],\n",
        "#         modulus_weight=config['modulus_weight'],\n",
        "#         reg_coeff=config['reg_coeff'],\n",
        "#         distance_metric=config['distance_metric']\n",
        "#     )\n",
        "\n",
        "\n",
        "#     # optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "#     optimizer = torch.optim.Adam(model.parameters(), lr= config['learning_rate'], betas=(0.9, 0.99))\n",
        "\n",
        "#     entity_dict = dataset.entity_dict  # Load entity dictionary from dataset\n",
        "#     relation_dict = dataset.relation_dict  # Load relation dictionary from dataset\n",
        "\n",
        "#     # Create a data object with the extracted edge indices and types\n",
        "#     data.train_edge_index = train_edge_index\n",
        "#     data.train_edge_type = train_edge_type\n",
        "#     data.valid_edge_index = valid_edge_index\n",
        "#     data.valid_edge_type = valid_edge_type\n",
        "#     data.test_edge_index = test_edge_index\n",
        "#     data.test_edge_type = test_edge_type\n",
        "\n",
        "\n",
        "#     # Train the model\n",
        "#     # train_model(model, learning_rate=config['learning_rate'], batch_size=config['batch_size'])\n",
        "\n",
        "#     # Training\n",
        "#     metrics = train(\n",
        "#         model=model,\n",
        "#         data=data,\n",
        "#         optimizer=optimizer,\n",
        "#         device=device,\n",
        "#         entity_dict=entity_dict,\n",
        "#         relation_dict=relation_dict,\n",
        "#         epochs=epochs,  # Use the epochs variable defined earlier\n",
        "#         batch_size=config['batch_size'],\n",
        "#         valid_freq=10  # Use the valid_freq variable defined earlier\n",
        "#     )\n",
        "\n",
        "# # Evaluate the model\n",
        "\n",
        "#     mrr_t = metrics['MRR']\n",
        "\n",
        "#     # Update the best configuration if this one performs better\n",
        "#     if mrr_t > best_mrr:\n",
        "#         best_mrr = mrr_t\n",
        "#         best_config = config\n",
        "\n",
        "# print(f\"Best configuration: {best_config} with MRR: {best_mrr}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "1b8gdP_4x5ji"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exclusion\n",
        "Excluding Mean Rank as we are hierarchical based."
      ],
      "metadata": {
        "id": "J0vE3IZrRh_q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "mpyhhj7toAz_"
      },
      "outputs": [],
      "source": [
        "# lr =  0.001 #0.003\n",
        "# use_gpu = torch.cuda.is_available()\n",
        "# if use_gpu:\n",
        "#     epochs = 100 #80\n",
        "#     valid_freq = 10\n",
        "# else:\n",
        "#     epochs = 10\n",
        "#     valid_freq = 10\n",
        "\n",
        "# device = torch.device('cuda' if use_gpu else 'cpu')\n",
        "\n",
        "# # Load dataset using CustomDataset class\n",
        "# data_path = '/content/sample_data'\n",
        "# dataset = CustomDataset(data_path)\n",
        "# data = dataset\n",
        "\n",
        "# # Extract edge indices and types\n",
        "# train_edge_index, train_edge_type = dataset.get_edge_indices_and_types(dataset.train_data)\n",
        "# valid_edge_index, valid_edge_type = dataset.get_edge_indices_and_types(dataset.valid_data)\n",
        "# test_edge_index, test_edge_type = dataset.get_edge_indices_and_types(dataset.test_data)\n",
        "\n",
        "# model = TransEEnhanced(data.num_entities,\n",
        "#                        data.num_relations,\n",
        "#                        embedding_dim=300,    #100,\n",
        "#                        margin=9).to(device)\n",
        "# # optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.99))\n",
        "\n",
        "# entity_dict = dataset.entity_dict  # Load entity dictionary from dataset\n",
        "# relation_dict = dataset.relation_dict  # Load relation dictionary from dataset\n",
        "\n",
        "# # Create a data object with the extracted edge indices and types\n",
        "# data.train_edge_index = train_edge_index\n",
        "# data.train_edge_type = train_edge_type\n",
        "# data.valid_edge_index = valid_edge_index\n",
        "# data.valid_edge_type = valid_edge_type\n",
        "# data.test_edge_index = test_edge_index\n",
        "# data.test_edge_type = test_edge_type\n",
        "\n",
        "# # Training\n",
        "# train(\n",
        "#     model=model,\n",
        "#     data=data,\n",
        "#     optimizer=optimizer,\n",
        "#     device=device,\n",
        "#     entity_dict=entity_dict,\n",
        "#     relation_dict=relation_dict,\n",
        "#     epochs=epochs,  # Use the epochs variable defined earlier\n",
        "#     batch_size=256,\n",
        "#     valid_freq=valid_freq  # Use the valid_freq variable defined earlier\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "use_gpu = torch.cuda.is_available()\n",
        "device = torch.device('cuda' if use_gpu else 'cpu')\n",
        "\n",
        "metrics = None\n",
        "# Load dataset using CustomDataset class\n",
        "data_path = '/content/sample_data'\n",
        "dataset = CustomDataset(data_path)\n",
        "data = dataset\n",
        "\n",
        "# Extract edge indices and types\n",
        "train_edge_index, train_edge_type = dataset.get_edge_indices_and_types(dataset.train_data)\n",
        "valid_edge_index, valid_edge_type = dataset.get_edge_indices_and_types(dataset.valid_data)\n",
        "test_edge_index, test_edge_type = dataset.get_edge_indices_and_types(dataset.test_data)\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "param_grid = {\n",
        "    \"embedding_dim\": 200,\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"margin\": 9.0,\n",
        "    \"batch_size\": 512,\n",
        "    \"phase_weight\": 0.5,\n",
        "    \"modulus_weight\": 2.0,\n",
        "    \"reg_coeff\": 1e-5,\n",
        "    \"distance_metric\": 1,  # 1 for L1 and 2 for L2\n",
        "    \"epochs\":200,\n",
        "    \"valid_freq\" : 10\n",
        "}\n",
        "\n",
        "# Initialize the model with the current hyperparameter configuration\n",
        "model = TransEEnhanced(\n",
        "    num_entities=data.num_entities,\n",
        "    num_relations=data.num_relations,\n",
        "    embedding_dim=param_grid['embedding_dim'],\n",
        "    margin=param_grid['margin'],\n",
        "    phase_weight=param_grid['phase_weight'],\n",
        "    modulus_weight=param_grid['modulus_weight'],\n",
        "    reg_coeff=param_grid['reg_coeff'],\n",
        "    distance_metric=param_grid['distance_metric']\n",
        ")\n",
        "\n",
        "\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr= param_grid['learning_rate'], betas=(0.9, 0.99))\n",
        "\n",
        "entity_dict = dataset.entity_dict  # Load entity dictionary from dataset\n",
        "relation_dict = dataset.relation_dict  # Load relation dictionary from dataset\n",
        "\n",
        "# Create a data object with the extracted edge indices and types\n",
        "data.train_edge_index = train_edge_index\n",
        "data.train_edge_type = train_edge_type\n",
        "data.valid_edge_index = valid_edge_index\n",
        "data.valid_edge_type = valid_edge_type\n",
        "data.test_edge_index = test_edge_index\n",
        "data.test_edge_type = test_edge_type\n",
        "\n",
        "# Training\n",
        "train(\n",
        "    model=model,\n",
        "    data=data,\n",
        "    optimizer=optimizer,\n",
        "    device=device,\n",
        "    entity_dict=entity_dict,\n",
        "    relation_dict=relation_dict,\n",
        "    epochs=param_grid['epochs'],  # Use the epochs variable defined earlier\n",
        "    batch_size=param_grid['batch_size'],\n",
        "    valid_freq=param_grid['valid_freq']  # Use the valid_freq variable defined earlier\n",
        ")\n"
      ],
      "metadata": {
        "id": "uP3CFuArdNED",
        "outputId": "ed37d885-77d7-432d-c4a4-1c008c77bb84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200, Loss: 32.4386\n",
            "Epoch 2/200, Loss: 31.3742\n",
            "Epoch 3/200, Loss: 30.5928\n",
            "Epoch 4/200, Loss: 29.7236\n",
            "Epoch 5/200, Loss: 28.6858\n",
            "Epoch 6/200, Loss: 27.5808\n",
            "Epoch 7/200, Loss: 26.4476\n",
            "Epoch 8/200, Loss: 25.2179\n",
            "Epoch 9/200, Loss: 23.9418\n",
            "Epoch 10/200, Loss: 22.7175\n",
            "Validation score: MRR = 0.1116, MR = 1227.2637, Hits@10 = 0.2189, Hits@3 = 0.1142, Hits@1 = 0.0577\n",
            "Epoch 11/200, Loss: 21.5832\n",
            "Epoch 12/200, Loss: 20.5375\n",
            "Epoch 13/200, Loss: 19.5213\n",
            "Epoch 14/200, Loss: 18.5055\n",
            "Epoch 15/200, Loss: 17.4942\n",
            "Epoch 16/200, Loss: 16.4507\n",
            "Epoch 17/200, Loss: 15.4090\n",
            "Epoch 18/200, Loss: 14.3649\n",
            "Epoch 19/200, Loss: 13.3313\n",
            "Epoch 20/200, Loss: 12.3136\n",
            "Validation score: MRR = 0.1954, MR = 418.8408, Hits@10 = 0.3399, Hits@3 = 0.2076, Hits@1 = 0.1243\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vs_oJCzJ3am6"
      },
      "source": [
        "# Example Workflow:\n",
        "## Input:\n",
        "\n",
        "**Dataset**: (Barack Obama, PresidentOf, United States), (Elon Musk, FounderOf, Tesla).\n",
        "**Embedding Initialization**:\n",
        "\n",
        "**Entities**: Barack Obama, United States, Elon Musk, Tesla.\n",
        "**Relations**: PresidentOf, FounderOf.\n",
        "**Training:**\n",
        "\n",
        "**Positive Triplets**: (Barack Obama, PresidentOf, United States).\n",
        "**Negative Sampling**: (Barack Obama, PresidentOf, RandomEntity).\n",
        "Evaluation:\n",
        "\n",
        "Metrics like **MRR, MR,** and **Hits@10** are computed during validation to measure the modelâ€™s performance.\n",
        "Prediction:\n",
        "\n",
        "**Query**: *(Elon Musk, FounderOf, ?)*\n",
        "**Prediction**: Tesla (most likely tail).\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}