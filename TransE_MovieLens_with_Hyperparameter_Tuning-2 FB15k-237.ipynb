{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "22d6e274",
      "metadata": {
        "id": "22d6e274"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "258146e1",
      "metadata": {
        "id": "258146e1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e9b37dc",
      "metadata": {
        "id": "7e9b37dc"
      },
      "source": [
        "# Step 1: Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "b51e15f0",
      "metadata": {
        "id": "b51e15f0"
      },
      "outputs": [],
      "source": [
        "# Load FB15K-237 dataset (example paths; update accordingly)\n",
        "train_path = '/content/data/train.txt'\n",
        "valid_path = '/content/data/valid.txt'\n",
        "test_path = '/content/data/test.txt'\n",
        "\n",
        "# Load triples into DataFrame\n",
        "def load_triples(file_path):\n",
        "    df = pd.read_csv(file_path, sep='\\t', header=None, names=['head', 'relation', 'tail'])\n",
        "    return df\n",
        "\n",
        "train_triples = load_triples(train_path)\n",
        "valid_triples = load_triples(valid_path)\n",
        "test_triples = load_triples(test_path)\n",
        "\n",
        "# Create entity and relation mappings\n",
        "all_entities = set(train_triples['head']).union(set(train_triples['tail']))\n",
        "all_relations = set(train_triples['relation'])\n",
        "\n",
        "entity_to_id = {entity: idx for idx, entity in enumerate(all_entities)}\n",
        "id_to_entity = {idx: entity for entity, idx in entity_to_id.items()}\n",
        "relation_to_id = {relation: idx for idx, relation in enumerate(all_relations)}\n",
        "id_to_relation = {idx: relation for relation, idx in relation_to_id.items()}\n",
        "\n",
        "# Map entities and relations to IDs\n",
        "def map_triples(triples):\n",
        "    triples['head'] = triples['head'].map(entity_to_id)\n",
        "    triples['relation'] = triples['relation'].map(relation_to_id)\n",
        "    triples['tail'] = triples['tail'].map(entity_to_id)\n",
        "    return triples[['head', 'relation', 'tail']]\n",
        "\n",
        "train_triples = map_triples(train_triples)\n",
        "valid_triples = map_triples(valid_triples)\n",
        "test_triples = map_triples(test_triples)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddddd7ae",
      "metadata": {
        "id": "ddddd7ae"
      },
      "source": [
        "# Step 2: Dataset Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "e2c2c3f1",
      "metadata": {
        "id": "e2c2c3f1"
      },
      "outputs": [],
      "source": [
        "# KnowledgeGraphDataset class\n",
        "class KnowledgeGraphDataset(Dataset):\n",
        "    def __init__(self, triples):\n",
        "        self.triples = torch.tensor(triples.values, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.triples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.triples[idx]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9738de1",
      "metadata": {
        "id": "b9738de1"
      },
      "source": [
        "# Step 3: Define the TransE Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "c48a7e0b",
      "metadata": {
        "id": "c48a7e0b"
      },
      "outputs": [],
      "source": [
        "# TransE Model\n",
        "class TransE(nn.Module):\n",
        "    def __init__(self, num_entities, num_relations, embedding_dim, margin, distance_metric='L1'):\n",
        "        super(TransE, self).__init__()\n",
        "        self.entity_embeddings = nn.Embedding(num_entities, embedding_dim)\n",
        "        self.relation_embeddings = nn.Embedding(num_relations, embedding_dim)\n",
        "        self.margin = margin\n",
        "        self.distance_metric = distance_metric\n",
        "\n",
        "        nn.init.xavier_uniform_(self.entity_embeddings.weight)\n",
        "        nn.init.xavier_uniform_(self.relation_embeddings.weight)\n",
        "\n",
        "    def forward(self, positive_triplets, negative_triplets):\n",
        "        pos_heads, pos_rels, pos_tails = positive_triplets[:, 0], positive_triplets[:, 1], positive_triplets[:, 2]\n",
        "        neg_heads, neg_rels, neg_tails = negative_triplets[:, 0], negative_triplets[:, 1], negative_triplets[:, 2]\n",
        "\n",
        "        pos_head_emb = self.entity_embeddings(pos_heads)\n",
        "        pos_rel_emb = self.relation_embeddings(pos_rels)\n",
        "        pos_tail_emb = self.entity_embeddings(pos_tails)\n",
        "\n",
        "        neg_head_emb = self.entity_embeddings(neg_heads)\n",
        "        neg_rel_emb = self.relation_embeddings(neg_rels)\n",
        "        neg_tail_emb = self.entity_embeddings(neg_tails)\n",
        "\n",
        "        p = 1 if self.distance_metric == 'L1' else 2\n",
        "\n",
        "        pos_distance = torch.norm(pos_head_emb + pos_rel_emb - pos_tail_emb, p=p, dim=1)\n",
        "        neg_distance = torch.norm(neg_head_emb + neg_rel_emb - neg_tail_emb, p=p, dim=1)\n",
        "\n",
        "        return pos_distance, neg_distance\n",
        "\n",
        "# Loss Function\n",
        "class MarginLoss(nn.Module):\n",
        "    def __init__(self, margin):\n",
        "        super(MarginLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, pos_distance, neg_distance):\n",
        "        return torch.mean(torch.relu(pos_distance - neg_distance + self.margin))\n",
        "\n",
        "# Initialize Model, Optimizer, and Loss\n",
        "num_entities = len(entity_to_id)\n",
        "num_relations = len(relation_to_id)\n",
        "embedding_dim = 20\n",
        "margin = 1.0\n",
        "learning_rate = 0.001\n",
        "distance_metric = 'L2'  # Choose either 'L1' or 'L2'\n",
        "\n",
        "model = TransE(num_entities, num_relations, embedding_dim, margin, distance_metric).to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criterion = MarginLoss(margin)\n",
        "\n",
        "# Precompute relation-specific tail entities\n",
        "def compute_relation_tails(triples):\n",
        "    relation_to_tails = {}\n",
        "    for _, row in triples.iterrows():\n",
        "        relation, tail = row['relation'], row['tail']\n",
        "        if relation not in relation_to_tails:\n",
        "            relation_to_tails[relation] = set()\n",
        "        relation_to_tails[relation].add(tail)\n",
        "    return relation_to_tails\n",
        "\n",
        "relation_to_tails = compute_relation_tails(train_triples)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3d35791",
      "metadata": {
        "id": "a3d35791"
      },
      "source": [
        "# Step 4: Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "6eb1402c",
      "metadata": {
        "id": "6eb1402c"
      },
      "outputs": [],
      "source": [
        "def train_model(model, optimizer, criterion, train_loader, num_epochs):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        for batch in train_loader:\n",
        "            batch = batch.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
        "\n",
        "            positive_triplets = batch\n",
        "            negative_triplets = batch.clone()\n",
        "            for i in range(len(negative_triplets)):\n",
        "                if np.random.rand() < 0.5:\n",
        "                    # Corrupt tail with a plausible entity\n",
        "                    relation = positive_triplets[i, 1].item()\n",
        "                    negative_triplets[i, 2] = np.random.choice(list(relation_to_tails[relation]))\n",
        "                else:\n",
        "                    # Corrupt head with a random entity\n",
        "                    negative_triplets[i, 0] = np.random.choice(num_entities)\n",
        "\n",
        "            pos_distance, neg_distance = model(positive_triplets, negative_triplets)\n",
        "            loss = criterion(pos_distance, neg_distance)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5575c25",
      "metadata": {
        "id": "d5575c25"
      },
      "source": [
        "# Step 5: Prediction and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "9a7aab08",
      "metadata": {
        "id": "9a7aab08"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    hits_at_10 = 0\n",
        "    mean_rank = 0\n",
        "    mean_reciprocal_rank = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            batch = batch.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
        "\n",
        "            heads, relations, tails = batch[:, 0], batch[:, 1], batch[:, 2]\n",
        "            for i in range(len(heads)):\n",
        "                head, relation, tail = heads[i], relations[i], tails[i]\n",
        "\n",
        "                head_emb = model.entity_embeddings(head)\n",
        "                rel_emb = model.relation_embeddings(relation)\n",
        "                target_emb = model.entity_embeddings(tail)\n",
        "\n",
        "                all_entities = model.entity_embeddings.weight\n",
        "                p = 1 if model.distance_metric == 'L1' else 2\n",
        "                scores = torch.norm(head_emb + rel_emb - all_entities, p=p, dim=1)\n",
        "                sorted_indices = torch.argsort(scores)\n",
        "\n",
        "                matches = (sorted_indices == tail).nonzero(as_tuple=True)\n",
        "                if matches[0].numel() > 0:  # Check if there are matches\n",
        "                    rank = matches[0].item() + 1\n",
        "                    mean_rank += rank\n",
        "                    mean_reciprocal_rank += 1 / rank\n",
        "                    if rank <= 10:\n",
        "                        hits_at_10 += 1\n",
        "\n",
        "    num_samples = len(test_loader.dataset)\n",
        "    print(f\"Hits@10: {hits_at_10 / num_samples:.4f}, Mean Rank: {mean_rank / num_samples:.4f}, MRR: {mean_reciprocal_rank / num_samples:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f11468b3",
      "metadata": {
        "id": "f11468b3"
      },
      "source": [
        "# Run evaluation on the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "N-tWPeo4HyzW",
      "metadata": {
        "id": "N-tWPeo4HyzW"
      },
      "source": [
        "learning rate λ for the stochastic gradient descent among {0.001,0.01,0.1}, the margin γ among {1,2,10} and the latent dimension\n",
        "kamong {20,50} on the validation set of each data set. The dissimilarity measure dwas set either\n",
        "to the L1 or L2 distance according to validation performance as well. Optimal configurations were:\n",
        "k = 20, λ = 0.01, γ = 2, and d= L1 on Wordnet; k = 50, λ = 0.01, γ = 1, and d= L1 on\n",
        "FB15k; k= 50, λ= 0.01, γ = 1, and d= L2 on FB1M"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "d2a0f3fc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2a0f3fc",
        "outputId": "66be1f70-85da-4709-cee3-0d458581e578"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 1502.2268\n",
            "Epoch 2/10, Loss: 621.8619\n",
            "Epoch 3/10, Loss: 361.2473\n",
            "Epoch 4/10, Loss: 287.7936\n",
            "Epoch 5/10, Loss: 248.1222\n",
            "Epoch 6/10, Loss: 223.8606\n",
            "Epoch 7/10, Loss: 203.2400\n",
            "Epoch 8/10, Loss: 189.5553\n",
            "Epoch 9/10, Loss: 180.4434\n",
            "Epoch 10/10, Loss: 171.6860\n",
            "Hits@10: 0.3488, Mean Rank: 272.4749, MRR: 0.2018\n",
            "Model saved to /content/data/TransE_FB15K237.pth\n"
          ]
        }
      ],
      "source": [
        "# Create Data Loaders\n",
        "train_data = KnowledgeGraphDataset(train_triples)\n",
        "valid_data = KnowledgeGraphDataset(valid_triples)\n",
        "test_data = KnowledgeGraphDataset(test_triples)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
        "valid_loader = DataLoader(valid_data, batch_size=128)\n",
        "test_loader = DataLoader(test_data, batch_size=128)\n",
        "\n",
        "# Train and Evaluate\n",
        "train_model(model, optimizer, criterion, train_loader, num_epochs=10)\n",
        "evaluate_model(model, test_loader)\n",
        "\n",
        "# Save the Model\n",
        "def save_model(model, file_path):\n",
        "    torch.save(model.state_dict(), file_path)\n",
        "    print(f\"Model saved to {file_path}\")\n",
        "\n",
        "save_model(model, \"/content/data/TransE_FB15K237.pth\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}