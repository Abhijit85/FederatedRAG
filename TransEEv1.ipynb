{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmSOksvuoAz3"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "MRLotX9cpCWr"
      },
      "outputs": [],
      "source": [
        "# whether you are using a GPU to run this Colab\n",
        "use_gpu = True\n",
        "# whether you are using a custom GCE env to run the Colab (uses different CUDA)\n",
        "custom_GCE_env = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFbWsOOboAz5",
        "outputId": "5cde1cbb-6c3d-4fcf-9d93-28ecdf7fc6f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.59.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.10.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.1)\n"
          ]
        }
      ],
      "source": [
        "%pip install openai\n",
        "%pip install python-dotenv\n",
        "# %pip install torch-geometric\n",
        "# %pip install torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
        "# %pip install torch-sparse -f https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "import os\n",
        "import re\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "# from torch_geometric.data import InMemoryDataset, DataLoader\n",
        "# import torch_geometric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uj9IXX0LoAz8"
      },
      "source": [
        "# Data Preparation and Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "Ktbb1Ambdnxv"
      },
      "outputs": [],
      "source": [
        "class CustomDataset:\n",
        "    def __init__(self, data_path: str):\n",
        "        \"\"\"\n",
        "        Custom Dataset class for loading and processing data without PyTorch Geometric.\n",
        "\n",
        "        Args:\n",
        "            data_path (str): Path to the dataset directory.\n",
        "        \"\"\"\n",
        "\n",
        "        #data_path = '/Users/abhi/GitHUB/FederatedRAG1/DataSets/FB15k-237'\n",
        "        # Paths to files\n",
        "        self.entity_dict_path = os.path.join(data_path, 'entities.dict')\n",
        "        self.relation_dict_path = os.path.join(data_path, 'relations.dict')\n",
        "        self.train_data_path = os.path.join(data_path, 'train.txt')\n",
        "        self.valid_data_path = os.path.join(data_path, 'valid.txt')\n",
        "        self.test_data_path = os.path.join(data_path, 'test.txt')\n",
        "\n",
        "        # Load dictionaries and datasets\n",
        "        self.entity_dict = self._read_dict(self.entity_dict_path)\n",
        "        self.relation_dict = self._read_dict(self.relation_dict_path)\n",
        "\n",
        "        self.train_data = self._read_data(self.train_data_path)\n",
        "        self.valid_data = self._read_data(self.valid_data_path)\n",
        "        self.test_data = self._read_data(self.test_data_path)\n",
        "\n",
        "        self.num_entities = len(self.entity_dict)\n",
        "        self.num_relations = len(self.relation_dict)\n",
        "\n",
        "    # def _read_dict(self, file_path):\n",
        "    #     \"\"\"Read a dictionary file mapping strings to integers.\"\"\"\n",
        "    #     with open(file_path, 'r') as f:\n",
        "    #         lines = f.readlines()\n",
        "    #     return {line.split('\\t')[0]: int(line.split('\\t')[1]) for line in lines}\n",
        "\n",
        "    def _read_dict(self, file_path: str):\n",
        "        \"\"\"\n",
        "        Read entity / relation dict.\n",
        "        Format: dict({id: entity / relation})\n",
        "        \"\"\"\n",
        "\n",
        "        element_dict = {}\n",
        "        with open(file_path, 'r') as f:\n",
        "            for line in f:\n",
        "                id_, element = line.strip().split('\\t')\n",
        "                element_dict[element] = int(id_)\n",
        "\n",
        "        return element_dict\n",
        "\n",
        "    def _read_data(self, file_path):\n",
        "        \"\"\"Read triples data and map to indices.\"\"\"\n",
        "        with open(file_path, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "        triples = [line.strip().split('\\t') for line in lines]\n",
        "        return [(self.entity_dict[h], self.relation_dict[r], self.entity_dict[t]) for h, r, t in triples]\n",
        "\n",
        "    def get_edge_indices_and_types(self, data):\n",
        "        \"\"\"Convert triples into edge indices and types for PyTorch tensors.\"\"\"\n",
        "        heads, relations, tails = zip(*data)\n",
        "        edge_index = torch.tensor([heads, tails], dtype=torch.long)  # Shape: (2, num_edges)\n",
        "        edge_type = torch.tensor(relations, dtype=torch.long)  # Shape: (num_edges,)\n",
        "        return edge_index, edge_type\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gh7tKibqoAz9"
      },
      "source": [
        "# TransGPT Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "dt4KLlz5oAz9"
      },
      "outputs": [],
      "source": [
        "class TransEEnhanced(nn.Module):\n",
        "    def __init__(self, num_entities, num_relations, embedding_dim, margin, distance_metric=1, # 1 for L1 and 2 for L2\n",
        "                 gamma=9.0, phase_weight=1.0, modulus_weight=3.5, epsilon=1.0):\n",
        "        super(TransEEnhanced, self).__init__()\n",
        "\n",
        "        # Basic TransE embeddings\n",
        "        self.entity_modulus = nn.Embedding(num_entities, embedding_dim)\n",
        "        self.entity_phase = nn.Embedding(num_entities, embedding_dim)\n",
        "        self.relation_modulus = nn.Embedding(num_relations, embedding_dim)\n",
        "        self.relation_phase = nn.Embedding(num_relations, embedding_dim)\n",
        "\n",
        "        # Margin and distance settings\n",
        "        self.margin = margin\n",
        "        self.distance_metric = distance_metric\n",
        "\n",
        "\n",
        "        # Hyperbolic and scaling settings\n",
        "        self.gamma = nn.Parameter(torch.Tensor([gamma]), requires_grad=False)\n",
        "        self.embedding_range = nn.Parameter(\n",
        "            torch.Tensor([(self.gamma.item() + epsilon) / embedding_dim]), requires_grad=False\n",
        "        )\n",
        "\n",
        "        # Weights for phase and modulus\n",
        "        self.phase_weight = phase_weight\n",
        "        self.modulus_weight = modulus_weight\n",
        "\n",
        "        # Initialization\n",
        "        nn.init.uniform_(self.entity_modulus.weight, a=-self.embedding_range.item(), b=self.embedding_range.item())\n",
        "        nn.init.uniform_(self.entity_phase.weight, a=-np.pi, b=np.pi)\n",
        "        nn.init.uniform_(self.relation_modulus.weight, a=-self.embedding_range.item(), b=self.embedding_range.item())\n",
        "        nn.init.uniform_(self.relation_phase.weight, a=-np.pi, b=np.pi)\n",
        "\n",
        "    def forward(self, head, relation, tail):\n",
        "        h_mod = self.entity_modulus(head)\n",
        "        h_phase = self.entity_phase(head)\n",
        "        r_mod = self.relation_modulus(relation)\n",
        "        r_phase = self.relation_phase(relation)\n",
        "        t_mod = self.entity_modulus(tail)\n",
        "        t_phase = self.entity_phase(tail)\n",
        "\n",
        "        # Modulus scoring: hyperbolic-inspired adjustment\n",
        "        modulus_score = torch.norm(h_mod * r_mod - t_mod, p=self.distance_metric, dim=-1)\n",
        "\n",
        "        # Phase scoring: advanced angular consistency\n",
        "        phase_diff = torch.abs(torch.sin((h_phase + r_phase - t_phase) / 2))\n",
        "        phase_score = torch.sum(phase_diff, dim=-1)\n",
        "\n",
        "        # Weighted combined score\n",
        "        score = self.modulus_weight * modulus_score + self.phase_weight * phase_score\n",
        "        return score\n",
        "\n",
        "    def compute_loss(self, positive_score, negative_score):\n",
        "        # Margin-based ranking loss\n",
        "        base_loss = F.relu(self.margin + positive_score - negative_score)\n",
        "\n",
        "        # Regularization terms for modulus and phase\n",
        "        modulus_regularization = torch.sum(torch.norm(self.entity_modulus.weight, p=self.distance_metric, dim=-1))\n",
        "        phase_regularization = torch.sum(torch.norm(self.entity_phase.weight, p=self.distance_metric, dim=-1))\n",
        "\n",
        "        # Total loss with regularization\n",
        "        # total_loss = base_loss.mean() + 1e-5 * (modulus_regularization + phase_regularization)\n",
        "        # total_loss = base_loss.mean() + 1e-3 * (modulus_regularization + phase_regularization)\n",
        "        total_loss = base_loss.mean() + 1e-4 * (modulus_regularization + phase_regularization)\n",
        "        return total_loss\n",
        "\n",
        "# Helper function to create corrupted edges\n",
        "def create_corrupted_edge_index(edge_index, edge_type, num_entities,negative_rate =1):\n",
        "      \"\"\"\n",
        "    Creates corrupted edge indices for negative sampling.\n",
        "\n",
        "    Args:\n",
        "        edge_index (torch.Tensor): The original edge indices.\n",
        "        edge_type (torch.Tensor): The edge types.\n",
        "        num_entities (int): The total number of entities.\n",
        "        negative_rate (int, optional): The number of negative samples per positive sample. Defaults to 1.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: The corrupted edge indices.\n",
        "    \"\"\"\n",
        "\n",
        "    # Repeat the original edge indices based on the negative rate\n",
        "      num_positive_edges = edge_index.shape[1]\n",
        "      repeated_edge_index = edge_index.repeat(1, negative_rate)\n",
        "      repeated_edge_type = edge_type.repeat(negative_rate)\n",
        "\n",
        "    # Create corrupted edges\n",
        "      corrupt_head_or_tail = torch.randint(high=2, size=(num_positive_edges * negative_rate,),\n",
        "                                         device=edge_index.device)\n",
        "      random_entities = torch.randint(high=num_entities,\n",
        "                                     size=(num_positive_edges * negative_rate,), device=edge_index.device)\n",
        "\n",
        "    # Corrupt either head or tail based on corrupt_head_or_tail\n",
        "      heads = torch.where(corrupt_head_or_tail == 1, random_entities,\n",
        "                          repeated_edge_index[0, :])\n",
        "      tails = torch.where(corrupt_head_or_tail == 0, random_entities,\n",
        "                          repeated_edge_index[1, :])\n",
        "\n",
        "      return torch.stack([heads, tails], dim=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXiKs2dKoAz-"
      },
      "source": [
        "# Train Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-VlS8124rZw"
      },
      "source": [
        "## Model: TransE\n",
        "**Embeddings:**\n",
        "Each entity and relation is represented as a vector in a high-dimensional space.\n",
        "The embeddings are initialized randomly and updated during training.\n",
        "**Distance Metric:**\n",
        "TransE predicts relationships by minimizing the distance between embeddings of head + relation - tail.\n",
        "A lower distance indicates a more likely relationship."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAtTXKqh5Mdo"
      },
      "source": [
        "## How Is the LLM Used?\n",
        "1. Prediction Refinement\n",
        "After the TransE model predicts relationships (e.g., a tail entity for a given head and relation), these predictions are passed to the LLM.\n",
        "The LLM evaluates the predictions, identifies errors, and suggests corrections or more plausible results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "vscode": {
          "languageId": "ruby"
        },
        "id": "rnLn4HqKdnxx"
      },
      "outputs": [],
      "source": [
        "def train(model, data, optimizer, device, entity_dict, relation_dict, epochs=50, batch_size=124, valid_freq=5):\n",
        "    train_edge_index = data.train_edge_index.to(device)\n",
        "    train_edge_type = data.train_edge_type.to(device)\n",
        "    valid_edge_index = data.valid_edge_index.to(device)\n",
        "    valid_edge_type = data.valid_edge_type.to(device)\n",
        "\n",
        "    best_valid_score = 0\n",
        "    valid_scores = None\n",
        "    test_scores = None\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "\n",
        "        # Normalize entity embeddings (modulus only)\n",
        "        entities_modulus_norm = torch.norm(model.entity_modulus.weight.data, dim=1, keepdim=True)\n",
        "        model.entity_modulus.weight.data = model.entity_modulus.weight.data / entities_modulus_norm\n",
        "\n",
        "        # Shuffle the training data\n",
        "        num_triples = train_edge_type.size(0)\n",
        "        shuffled_indices = torch.randperm(num_triples)\n",
        "        shuffled_edge_index = train_edge_index[:, shuffled_indices]\n",
        "        shuffled_edge_type = train_edge_type[shuffled_indices]\n",
        "\n",
        "        # negative_edge_index = create_corrupted_edge_index(shuffled_edge_index, shuffled_edge_type, data.num_entities)\n",
        "        negative_edge_index = create_corrupted_edge_index(shuffled_edge_index, shuffled_edge_type, data.num_entities, negative_rate=5)  # Generate 5 negative samples per positive sample\n",
        "\n",
        "        total_loss = 0\n",
        "        total_size = 0\n",
        "\n",
        "        for batch_start in range(0, num_triples, batch_size):\n",
        "            batch_end = min(batch_start + batch_size, num_triples)\n",
        "            batch_edge_index = shuffled_edge_index[:, batch_start:batch_end]\n",
        "            batch_negative_edge_index = negative_edge_index[:, batch_start:batch_end]\n",
        "            batch_edge_type = shuffled_edge_type[batch_start:batch_end]\n",
        "\n",
        "            # Compute positive and negative scores for TransEEnhanced\n",
        "            positive_score = model(batch_edge_index[0], batch_edge_type, batch_edge_index[1])\n",
        "            negative_score = model(batch_negative_edge_index[0], batch_edge_type, batch_negative_edge_index[1])\n",
        "\n",
        "            # Compute loss using TransEEnhanced's loss function\n",
        "            loss = model.compute_loss(positive_score, negative_score)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item() * (batch_end - batch_start)\n",
        "            total_size += batch_end - batch_start\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / total_size:.4f}\")\n",
        "\n",
        "        # Validation at regular intervals\n",
        "        if (epoch + 1) % valid_freq == 0:\n",
        "            # mrr_score, mr_score, hits_at_10 = evaluate_model(\n",
        "                # Introduced the Hit@1,3\n",
        "            mrr_score, mr_score, hits_at_10, hits_at_3, hits_at_1 = evaluate_model(\n",
        "                model, valid_edge_index, valid_edge_type, data.num_entities, device\n",
        "            )\n",
        "            # print(f\"Validation score: MRR = {mrr_score:.4f}, MR = {mr_score:.4f}, Hits@10 = {hits_at_10:.4f}\")\n",
        "            print(f\"Validation score: MRR = {mrr_score:.4f}, MR = {mr_score:.4f}, Hits@10 = {hits_at_10:.4f}, Hits@3 = {hits_at_3:.4f}, Hits@1 = {hits_at_1:.4f}\")\n",
        "            # Track best validation score\n",
        "            if mrr_score > best_valid_score:\n",
        "                best_valid_score = mrr_score\n",
        "                # test_mrr, test_mr, test_hits_at_10 = evaluate_model(\n",
        "                test_mrr, test_mr, test_hits_at_10,test_hits_at_3,test_hits_at_1 = evaluate_model(\n",
        "                    model, data.test_edge_index.to(device), data.test_edge_type.to(device), data.num_entities, device\n",
        "                )\n",
        "                test_scores = (test_mrr, test_mr, test_hits_at_10,test_hits_at_3,test_hits_at_1)\n",
        "\n",
        "    print(f\"Test scores from the best model (MMR, MR, Hits@10): {test_scores}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyUVJhNroAz-"
      },
      "source": [
        "# Evaluate Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tzLhqtE4XK_"
      },
      "source": [
        "## Prediction:\n",
        "After training, the model can predict missing relationships by ranking possible tail entities for a given (head, relation, ?).\n",
        "Example Query:\n",
        "Input: (Steve Jobs, FounderOf, ?)\n",
        "Output: Apple (highest-ranked entity)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, edge_index, edge_type, num_entities, device, eval_batch_size=32):\n",
        "    model.eval()\n",
        "    num_triples = edge_type.size(0)\n",
        "    mrr_score = 0\n",
        "    mr_score = 0\n",
        "    hits_at_10 = 0\n",
        "    hits_at_3 = 0\n",
        "    hits_at_1 = 0\n",
        "    num_predictions = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx in range(math.ceil(num_triples / eval_batch_size)):\n",
        "            batch_start = batch_idx * eval_batch_size\n",
        "            batch_end = min((batch_idx + 1) * eval_batch_size, num_triples)\n",
        "            batch_edge_index = edge_index[:, batch_start:batch_end]\n",
        "            batch_edge_type = edge_type[batch_start:batch_end]\n",
        "            batch_size = batch_edge_type.size(0)\n",
        "\n",
        "            all_entities = torch.arange(num_entities, device=device).unsqueeze(0).repeat(batch_size, 1)\n",
        "            head_repeated = batch_edge_index[0, :].reshape(-1, 1).repeat(1, num_entities)\n",
        "            relation_repeated = batch_edge_type.reshape(-1, 1).repeat(1, num_entities)\n",
        "\n",
        "            head_squeezed = head_repeated.reshape(-1)\n",
        "            relation_squeezed = relation_repeated.reshape(-1)\n",
        "            all_entities_squeezed = all_entities.reshape(-1)\n",
        "\n",
        "            entity_index_replaced_tail = torch.stack((head_squeezed, all_entities_squeezed))\n",
        "            predictions = model(entity_index_replaced_tail[0], relation_squeezed, entity_index_replaced_tail[1])\n",
        "            predictions = predictions.reshape(batch_size, -1)\n",
        "            gt = batch_edge_index[1, :].reshape(-1, 1)\n",
        "\n",
        "            mrr_score += mrr(predictions, gt)\n",
        "            mr_score += mr(predictions, gt)\n",
        "            hits_at_10 += hit_at_k(predictions, gt, device=device, k=10)\n",
        "            hits_at_3 += hit_at_k(predictions, gt, device=device, k=3)\n",
        "            hits_at_1 += hit_at_k(predictions, gt, device=device, k=1)\n",
        "            num_predictions += batch_size\n",
        "\n",
        "    mrr_score = mrr_score / num_predictions\n",
        "    mr_score = mr_score / num_predictions\n",
        "    hits_at_10 = hits_at_10 / num_predictions\n",
        "    hits_at_3 = hits_at_3 / num_predictions\n",
        "    hits_at_1 = hits_at_1 / num_predictions\n",
        "    return mrr_score, mr_score, hits_at_10, hits_at_3, hits_at_1\n",
        "\n",
        "\n",
        "# Metric Functions\n",
        "def mrr(predictions, gt):\n",
        "    indices = predictions.argsort()\n",
        "    return (1.0 / (indices == gt).nonzero()[:, 1].float().add(1.0)).sum().item()\n",
        "\n",
        "def mr(predictions, gt):\n",
        "    indices = predictions.argsort()\n",
        "    return ((indices == gt).nonzero()[:, 1].float().add(1.0)).sum().item()\n",
        "\n",
        "def hit_at_k(predictions, gt, device, k=10):\n",
        "    # Generalized Hits@k calculation\n",
        "    zero_tensor = torch.tensor([0], device=device)\n",
        "    one_tensor = torch.tensor([1], device=device)\n",
        "    _, indices = predictions.topk(k=k, largest=False)\n",
        "    return torch.where(indices == gt, one_tensor, zero_tensor).sum().item()\n"
      ],
      "metadata": {
        "id": "umUkkfaT9uVb"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4a5ovUh4oAz_"
      },
      "source": [
        "# Start Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6FOxlII4jEq"
      },
      "source": [
        "## Positive Triplets:\n",
        "The dataset provides positive examples in the form of valid (head, relation, tail) triplets.\n",
        "## Negative Sampling:\n",
        "For each positive triplet, a corrupted version is generated by replacing either the head or tail with a random entity.\n",
        "## Loss Function:\n",
        "The model uses margin-based ranking loss:\n",
        "Ensures valid triplets are closer in embedding space than invalid ones by at least a predefined margin."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Last good run\n",
        "Epoch 189/300, Loss: 0.8249\n",
        "Epoch 190/300, Loss: 0.8266\n",
        "Validation score: MRR = 0.2752, MR = 162.0998, Hits@10 = 0.4444, Hits@3 = 0.2932, Hits@1 = 0.1925"
      ],
      "metadata": {
        "id": "J0vE3IZrRh_q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpyhhj7toAz_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "096d00ba-93a0-4339-9937-04b25b2275b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500, Loss: 43.1559\n",
            "Epoch 2/500, Loss: 9.0636\n",
            "Epoch 3/500, Loss: 6.5673\n",
            "Epoch 4/500, Loss: 5.9611\n",
            "Epoch 5/500, Loss: 5.7647\n",
            "Epoch 6/500, Loss: 5.6351\n"
          ]
        }
      ],
      "source": [
        "lr =  0.005 #0.003\n",
        "use_gpu = torch.cuda.is_available()\n",
        "if use_gpu:\n",
        "    epochs = 500 #80\n",
        "    valid_freq = 10\n",
        "else:\n",
        "    epochs = 10\n",
        "    valid_freq = 10\n",
        "\n",
        "device = torch.device('cuda' if use_gpu else 'cpu')\n",
        "\n",
        "# Load dataset using CustomDataset class\n",
        "data_path = '/content/sample_data'\n",
        "dataset = CustomDataset(data_path)\n",
        "data = dataset\n",
        "\n",
        "# Extract edge indices and types\n",
        "train_edge_index, train_edge_type = dataset.get_edge_indices_and_types(dataset.train_data)\n",
        "valid_edge_index, valid_edge_type = dataset.get_edge_indices_and_types(dataset.valid_data)\n",
        "test_edge_index, test_edge_type = dataset.get_edge_indices_and_types(dataset.test_data)\n",
        "\n",
        "model = TransEEnhanced(data.num_entities,\n",
        "                       data.num_relations,\n",
        "                       embedding_dim=50,\n",
        "                       margin=4.0).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "entity_dict = dataset.entity_dict  # Load entity dictionary from dataset\n",
        "relation_dict = dataset.relation_dict  # Load relation dictionary from dataset\n",
        "\n",
        "# Create a data object with the extracted edge indices and types\n",
        "data.train_edge_index = train_edge_index\n",
        "data.train_edge_type = train_edge_type\n",
        "data.valid_edge_index = valid_edge_index\n",
        "data.valid_edge_type = valid_edge_type\n",
        "data.test_edge_index = test_edge_index\n",
        "data.test_edge_type = test_edge_type\n",
        "\n",
        "# Training\n",
        "train(\n",
        "    model=model,\n",
        "    data=data,\n",
        "    optimizer=optimizer,\n",
        "    device=device,\n",
        "    entity_dict=entity_dict,\n",
        "    relation_dict=relation_dict,\n",
        "    epochs=epochs,  # Use the epochs variable defined earlier\n",
        "    batch_size=128,\n",
        "    valid_freq=valid_freq  # Use the valid_freq variable defined earlier\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "\n",
        "# # Check if CUDA is available\n",
        "# if torch.cuda.is_available():\n",
        "#     # Get the device properties\n",
        "#     device_properties = torch.cuda.get_device_properties(0)  # 0 for the first GPU\n",
        "\n",
        "#     # Get total memory in bytes\n",
        "#     total_memory = device_properties.total_memory\n",
        "\n",
        "#     # Get allocated memory in bytes\n",
        "#     allocated_memory = torch.cuda.memory_allocated(0)\n",
        "\n",
        "#     # Get reserved memory in bytes\n",
        "#     reserved_memory = torch.cuda.memory_reserved(0)\n",
        "\n",
        "#     # Calculate free memory in bytes\n",
        "#     free_memory = total_memory - allocated_memory - reserved_memory\n",
        "\n",
        "#     # Print the results in GB\n",
        "#     print(f\"Total CUDA memory: {total_memory / (1024**3):.2f} GB\")\n",
        "#     print(f\"Allocated CUDA memory: {allocated_memory / (1024**3):.2f} GB\")\n",
        "#     print(f\"Reserved CUDA memory: {reserved_memory / (1024**3):.2f} GB\")\n",
        "#     print(f\"Free CUDA memory: {free_memory / (1024**3):.2f} GB\")\n",
        "\n",
        "# else:\n",
        "#     print(\"CUDA is not available.\")"
      ],
      "metadata": {
        "id": "I0CTDsvPvsCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vs_oJCzJ3am6"
      },
      "source": [
        "# Example Workflow:\n",
        "## Input:\n",
        "\n",
        "**Dataset**: (Barack Obama, PresidentOf, United States), (Elon Musk, FounderOf, Tesla).\n",
        "**Embedding Initialization**:\n",
        "\n",
        "**Entities**: Barack Obama, United States, Elon Musk, Tesla.\n",
        "**Relations**: PresidentOf, FounderOf.\n",
        "**Training:**\n",
        "\n",
        "**Positive Triplets**: (Barack Obama, PresidentOf, United States).\n",
        "**Negative Sampling**: (Barack Obama, PresidentOf, RandomEntity).\n",
        "Evaluation:\n",
        "\n",
        "Metrics like **MRR, MR,** and **Hits@10** are computed during validation to measure the model’s performance.\n",
        "Prediction:\n",
        "\n",
        "**Query**: *(Elon Musk, FounderOf, ?)*\n",
        "**Prediction**: Tesla (most likely tail).\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}